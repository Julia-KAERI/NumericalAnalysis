---
title: "이미지 프로세싱의 기초"

number-sections: true
number-depth : 3
crossref:
  chapters: false
---

{{< include ../../latexmacros.qmd >}}

</br>

## 소개

### 이미지

- 우리의 시각에서 감지하는 바와 같은 2차원 이미지 일 수도 있지만, 측정에서 얻는 2차원 데이터 일 수 도 있다. 
- 여기서 다루는 이미지는 디지털 이미지이다. 정해진 크기의 수로 이루어진 2차원 배열을 이미지라고 통칭한다.
- 2차원 배열을 $f[i,j]$ 로 표기하며, 행렬과 같이 $i$ 는 세로 방향의 인덱스, $j$ 는 가로 방향의 인덱스이다.

프로그래밍에서 2차원 배열의 인덱스는 관례적으로 세로축-가로축 순서이지만, 수학에서 함수로서 표현할 때는 관례적으로 가로축-세로축 순서이다. 이것이 매우 혼동을 일으키지만 이 관례를 계속 사용하기로 한다. 즉

$$
\boxed{
    f[i,\,j]= f(j, i)
}
$$

이다. 

</br>

### 여기서

- Julia 에는 `Images.jl` 이라는 이미지 처리 라이브러리가 있지만,
  - 모든 데이터값을 $[0,\,1]$ 사이의 고정 소수(fixed point number) 로 처리하며, 원래 이미지가 가지고 있던 0 부터 255 사이의 부호 없는 정수값을 숨긴다. 
  - [opencv](https://opencv.org/) 에 비해 기능이 부족하고 무엇보다 느리다.
  - [OpenCV.jl](https://github.com/JuliaImages/OpenCV.jl) 이라는 `opencv` 의 julia 포팅이 있다.
- 그런데 `OpenCV.jl` 은
  - 기본 이미지 배열 타입은 `OpenCV.Mat` 이며 julia 의 `Array` 와 유사하지만 같지는 않다. `Array` 에서 사용하는 연산중 많은 것을 사용 할 수 없다. 파이썬의 경우는 `opencv2` 의 배열은 `numpy` 의 배열인데...
  - 흑백 이미지라도 `OpenCV.Mat` 은 3차원 배열이다. 
  - `OpenCV.Mat` 에 대한 연산 (배열간, 배열과 스칼라 사이의 사칙연산을 포함하여) 을 모두 다시 쓰느니 `OpenCV.Mat` 과 julia `Array` 사이의 변환 함수를 사용하겠다.
  - `OpenCV.Mat` 의 배열의 저장 순서는 C++ 이나 파이썬 과 같이 행 우선 방식이지만 Julia 는 열 우선 방식이다. 따라서 변환시 이를 고려해야 한다.
- Julia 의 [TestImages.jl](https://testimages.juliaimages.org/stable/) 은 다양한 무료 이미지를 다운로드 받을 수 있도록 해 준다. 여기서의 이미지 처리에 사용하는 이미지는 특별한 언급이 없는 한 여기로부터 얻는다.

</br>

`OpenCV.jl` 을 julia 에서 사용하기 위해 다음과 같은 함수를 사용한다. 앞으로의 모든 코드는 

```julia
using OpenCV, TestImages
cv = OpenCV;

# Julia Matrix to OpenCV.MAT 변환
function arr2mat(arr::Matrix{T}) where T<:Real
    cv.Mat(permutedims(stack([arr, ]), [3,2,1]))
end

# Julia Image to Matrix 변환
function img2arr(img)
    T = typeof(img[1, 1].val.i)
    broadcast(q->T(q.val.i),img)
end

# Julia Image to OpenCV.Mat 변환
function img2mat(img) 
    T = typeof(img[1, 1].val.i)
    tm = broadcast(q->T(q.val.i),img)
    cv.Mat(permutedims(stack([tm, ]), [3,2,1]))
end

# OpenCV.Mat to Julia Matrix 변환
function mat2arr(mat::OpenCV.Mat)
    return permutedims(mat.data, [3,2,1])
end
```

</br>

## 점 기준 이미지 가공

- 각 픽셀 단위의 이미지 처리를 의미한다. 즉 픽셀에 대한 연신이 다른 픽셀의 정보와 독립적으로 이루어진다.

- Gray scale image $f[i, j]$ 를 생각하자. $0\le f[i,\,j] \le 255$ 이다.

</br>

### 픽셀 반전법에 의한 이미지 가공 {#sec-ImageProcessing_pixel_inversion}

상수 $a$ 와 $b>0$ 에 대해 
$$
T_i[f](i, j) = a-b f(i, j),\qquad 0 \le T[f] \le 255
$$

인 이미지 연산을 픽셀 반전법 이라고 한다. $a=255,\, b=1$ 일 경우 완전한 흑백 반전이다. `TestImages.jl` 로부터 테스트 이미지를 다운받아 처리하였다.

```julia
img0= testimage_dip3e("Fig0108(a) (corn-fluorescence).tif")
img1 = img2arr(img0)
img2 = (UInt8(255) .- img1)
r = arr2mat(cat(img1, img2;dims=2))
```
![원본 이미지(좌) 와 반전된 이미지](notebooks/inversion.jpg){#fig-ImageProcessing_inversion}

</br>

### $\gamma$-correction (or $\gamma$-encoding) {#sec-ImageProcessing-gamma_correction}

- $\gamma>0$ 에 대해 다음과 같이 변환한다.
$$
T_\gamma [f](i, j)  = f(i, j)^\gamma 
$$

- $\gamma$ 값이 $1$ 보다 상당히 크면 픽셀 값이 클수록, $\gamma$ 값이 $1$ 보다 상당히 작으면 픽셀값이 작을수록 대조가 현저해진다.
- $0\le f\le 255$ 일 때 $\gamma<1$ 이면 $f^\gamma < 255$ 이며 $\gamma>1$ 이면 $f^\gamma>255$ 일 수 있으므로 최대값이 255가 넘지 않도록 해 준다.
- 원본 이미지가 1024x1024 로 크기 때문에 그 크기를 줄여주었다.

```julia
img0= testimage_dip3e("Fig0227(a)(washington_infrared).tif")
img1 = cv.resize(img2mat(img0), cv.Size{Int32}(256, 256))
img2 = arr2mat(round.(UInt8, ((img1./255).^0.5)*255))
img3 = arr2mat(round.(UInt8, ((img1./255).^2)*255))
img4 = arr2mat(round.(UInt8, ((img1./255).^5)*255));
arr2mat(cat(img1, img2, img3, img4; dims=2))
```

![맨 왼쪽부터 $\gamma=1$, $\gamma=0.5$, $\gamma=2$, $\gamma=5$](notebooks/gamma_correction.png){#fig-ImageProcessing_gamma_correction}

- $x\in (0,\,1)$ 에 대해 $\gamma<1$ 이면 $x^\gamma > x$ 이므로 화소 값이 높은 쪽으로 몰린다. 반대로 $\gamma>1$ 이면 $x^\gamma < x$ 이므로 화소 값이 낮은 쪽으로 몰린다.



</br>

### 히스토그램 균등화 {#sec-ImageProcessing_histogram_equalization}

이미지의 각 픽셀은 0 에서 255 사이의 정수값을 가진다. 그 값의 빈도는 이미지의 성질을 파악하는데 중요하다. 예를 들어 @fig-ImageProcessing_gamma_correction 의 $\gamma$ 에 대한 히스토그램은 다음과 같다.

```julia

# opencv 의 calcHist 함수를 julia 에서 쓰기 편하게 변환함.
function histogram1d(mat::OpenCV.Mat{T}) where T<:Union{UInt8, UInt16}
    tm = Int32(typemax(T))
    v = cv.calcHist(cv.InputArray[mat,], Int32[0], fill(UInt8(1), size(img1)), Int32[tm+1], Float32[0, tm+1])
    return (0:1:tm, Int64.(v[1,1,:]))    
end

fig = Figure()
ax = Axis(fig[1,1])
for (img, g) in zip([img1, img2, img3, img4], [1.0, 0.5, 2, 5])
    b, v = histogram1d(img)
    lines!(ax, b, v, label = L"\gamma = %$g")
end
axislegend()
fig
```
![@fig-ImageProcessing_gamma_correction 의 $\gamma$ 값에 따른 히스토그램](notebooks/histogram_gamma.png){#fig-ImageProcessing_histogram_gamma_correction width=400}

</br>

위의 그림에서 $\gamma=5$ 일 때의 히스토그램은 낮은 값으로 몰려 있다. 혹은 이미지 중에는 전체 256 의 채널 갑 중에 어떤 값을 중심으로 몰려 있을 수 있다. 이런 경우 컨트라스트를 조절 하기 위해 앞서의 $\gamma$-correction 방법으로는 개선이 크게 되지 않는다. 이 때 사용하는 방법이 히스토그램 균등화이다. 한 채널을 중심으로 몰려 있는 히스토그램을 균등화 한다. 


원래의 히스토그램을 변수 $r$ 에 대해 $h(r)$ 이며 $r$ 은 $0$ 부터 $L-1$ (여기서는 255) 까지 가질 수 있고 $h(r)$ 확률 별수 $r$ 에 대한 확률 밀도에 비례하는 값이라고 가정하자. $p_r(r)$ 을 확률밀도라고 하면

$$
p_r(r) = \dfrac{h(r)}{\int_0^L h(r')\,dr'}
$$ {#eq-ImageProcessing_histogram_equalization_1}

이며 이 때 새로운 변수 $s$ 를 다음과 같이 정의한다.

$$
s=(L-1)\int_{0}^r p_r(r')\,dr'.
$$ {#eq-ImageProcessing_histogram_equalization_2}

그렇다면

$$
\dfrac{ds}{dr} = (L-1)p_r(r)
$$ {#eq-ImageProcessing_histogram_equalization_3}

이며 새로운 변수 $s$ 로 변환된 $p_r(r)$ 은

$$
p_s(s) = p_r(r)\left|\dfrac{ds}{dr}\right| = \dfrac{1}{L-1}
$$  {#eq-ImageProcessing_histogram_equalization_4}

이다. 즉 새로운 변수 $s$ 에 대해 $p_s(s)$ 는 항상 같은 값을 갖게 된다. 

즉 어떤 픽셀의 강도가 $r$ 이라면 새로운 강도는 $s$ 가 된다. $r=0,\,1,\ldots,\,L-1$ 의 값을 가지므로 이에 대한 $s$ 값을  

$$
s(r) = \text{round}\left[(L-1)\sum_{i=1}^r \dfrac{h(i)}{\sum_{j=1}^{L-1} h(j)}\right]
$${#eq-ImageProcessing_histogram_equalization_4}

를 이용혜 계산한다. $\text{round}(t)$ 는 $t$ 를 반올림 하는 함수이다. `OpenCV` 에서는 `equalizeHist()` 함수로 구현되었으며 여기서는 이 함수를 사용한다.


</br>

![원본, $\gamma=5$ 처리된 이미지, 히스토그램 균등화 된 이미지](notebooks/equalize_histogram_1.png)

```julia
img5 = cv.equalizeHist(img4)
arr2mat(cat(img1, img4, img5; dims=2))
```

![원본, $\gamma=5$ 처리된 이미지, 히스토그램 균등화 된 이미지의 히스토그램](notebooks/equalize_histogram.png)

</br>

## 노이즈 생성

노이즈의 원인은 다양하며, 노이즈에 대한 처리 방법도 다양하고 매우 중요하다. 노이즈 처리에 대해 알아야 하는데 우리가 일반적으로 얻는 영상은 노이지그 이미 제거된 것이 많으며, 노이즈 제거 기법을 알아보기 위해 임의로 노이즈를 생성할 수 있어야 한다. 여기서는 가장 대표적인 가우시안 노이즈와 흑백 노이즈(salt-pepper noise) 에 대해 간락히 알아보기로 한다.

</br>

### 가우시안 노이즈

가우시안 노이즈는 어떤 평균에 대해 가우시안 분포를 갖는 노이즈이다. 즉 노이즈를 생성시키려면 평균값과 표준편차로 정의되는 가우시안 분포에 따라 임의의 점에 대해 생성해야 한다.








</br>

## 아핀 변환과 보간법

### 아핀 변환 {#sec-ImageProcessing_Affine_transform}

이미지를 이용해 흔히 하는 작업이 확대, 축소, 회전, 직선이동이 있으며 이를 **아핀 변환(Affine transformation)** 이라고 한다. 아핀 변환은 $3\times 3$ 가역행렬 $\bf{T}$ 에 의해 정해지는 다음과 같은 변환을 의미한다. 

$$
\begin{bmatrix} x' \\ y' \\1\end{bmatrix} = \bf{T} \begin{bmatrix} x \\ y \\ 1\end{bmatrix}
$$

예를 들어 $\theta$ 만큼의 반시계 방향 회전 변환 $\bf{T}_\theta$ 는

$$
\bf{T}_\theta = \begin{bmatrix} \cos \theta & \sin \theta & 0 \\ -\sin \theta & \cos \theta & 0 \\ 0 & 0 & 1\end{bmatrix}
$$

이며 $x$ 방향으로 $d_x$ $y$ 방향으로 $d_y$ 만큼의 회전 변환 $\bf{T}_\bf{d}$ 는

$$
\bf{T}_\bf{d} = \begin{bmatrix}  1 & 0 & d_x \\ 0 & 1 & d_y \\ 0 & 0 & 1\end{bmatrix}
$$

이다. 또한 $x$ 축 혹은 $y$ 축 방향으로 기울이는 [전단 변환(shear tranformation)](https://en.wikipedia.org/wiki/Shear_mapping) $\bf{T}_{Sx},\, \bf{T}_{Sy}$ 은 각각

$$
\bf{T}_{Sx} = \begin{bmatrix} 1 & s_x & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{bmatrix},\qquad \bf{T}_{Sy} = \begin{bmatrix} 1 & 1 & s_y \\ 0 & 1 & 0 \\ 0 & 0 & 1\end{bmatrix}
$$

이다. 또한 $x$ 축 방향으로 $a_x$ 배 만큼, $y$ 축 방향으로 $a_y$ 배 만큼 키우거나 줄이는 변환 $\bf{T}_c$ 는

$$
\bf{T}_c = \begin{bmatrix} a_x & 0 & 0 \\ 0 & a_y & 0 \\ 0 & 0 & 1\end{bmatrix}
$$

이다. 

아핀 변환 $T$ 에 대해 이미지 $f$ 를 변환시킬 때 $g=T[f]$ 인 이미지를 얻고자 한다고 하자. 그렇다면 $g[i, j]$ 는 어떻게 얻을 것인가? $g$ 는 이미지 이므로 $i,\,j$ 는 정수이다. 아핀 변환의 역변환 $T^{-1}$ 을 생각하자. 아핀변환은 선형 가역변환이므로 항상 역변환이 존재한다. 즉

$$
\begin{bmatrix}x \\ y \\ 1\end{bmatrix} = T^{-1}\begin{bmatrix} x' \\ y' \\ 1\end{bmatrix}
$$

이다. 우리는 $g(j,\,i)$ 값을 알고 싶지만 아핀 역변환에 의한 $x,\,y$ 는 정수가 아니므로 정확한 값을 얻을 수 없다. 이 때 보간법(interpolation)을 사용한다.

</br>

### 보간법 

이미지 $f[i,\,j]=f(j,\,i)$ 는 자연수인 $i,\,j$ 에 대해 정해져 있다. $x,\,y$ 가 자연수가 아닐 때 $f(x,\,y)$ 값은 **보간법(interpolation)** 으로 정한다.

</br>

#### **최근접 이웃 보간** 

$(x,\,y)$ 에 가장 가까운 정수 값으로 보간하는 것이다. 즉
$$
f(x,\,y) \mapsto f(\text{round}(x),\, \text{round}(y))
$${#eq-ImageProcessing_nearest_neighbor_interpolation}

를 사용한다. 가장 간단하면서도 빠르지만 변환된 이미지의 품질이 좋지 못하다.

</br>

#### **이중 선형 보간**

$x,\,y$ 에 대해 

$$
i\le y < i+1,\, j\le x<j+1
$$ 

인 정수 $i,\,j$ 를 찾아 $f[i,j]$, $f[i,j+1]$, $f[i+1, j]$, $f[i+1, j+1]$ 인 네 점을 이용한다. 

$$
\begin{aligned}
f(x,\,y) &= (1-x+j)(1-y+i)f(j, i) + (1-x+j)(y-i)f(j,\,i+1) \\[0.3em]
&+ (x-j)(1-y+i)f(j+1, i) + (x-j)(y-i)f(j+1, i+1).
\end{aligned}
$$ {#eq-ImageProcessing_bilinear_interpolation}

앞서의 최근접 이웃 보간보다는 계산량이 많고 이미지 품질이 좋다.

</br>

#### **이중 큐빅 보간**

$x,\,y$ 에 대해 
$$
i\le y < i+1,\, j\le x<j+1
$$ 

인 정수 $i,\,j$ 를 찾아 $f[i+k,j+m]$, $k,\,m = -1,\,0,\,1,\,2$ 인 16개의 점을 이용한다. 

$$
d(s) = \left\{\begin{array}{ll} \dfrac{3|s|^3}{2}-\dfrac{5|s|^2}{2}+1, & 0 \le |s| < 1, \\ -\dfrac{|s|^3}{2}+\dfrac{5|s|^2}{2}-4|s|+2, \qquad & 1\le |s|<2 , \\ 0 & |s|>2 \end{array}\right.
$$

에 대해 다음 함수를 이용하여 계산한다.
$$
f(x,\,y) = \sum_{k=-1}^2 \sum_{m=-1}^2 f(j+k, i+m)d(x- j-k)d(y - i-m)
$$

</br>

아래 그림은 1차원 데이터의 보간법과 2차원 이미지의 보간법을 설명하는 그림이다.

![1차원 및 2차원 보간법(출처 : https://en.wikipedia.org/wiki/Bicubic_interpolation) By <a href="//commons.wikimedia.org/wiki/User:Cmglee" title="User:Cmglee">Cmglee</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons Attribution-Share Alike 4.0">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=53064904">Link</a>](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Comparison_of_1D_and_2D_interpolation.svg/2880px-Comparison_of_1D_and_2D_interpolation.svg.png){#fig-ImageProcessing_interpolations width=500}

</br>


`TestImages.jl` 로 부터 $256\times 256$ 이미지 `lena_gray_256` 을 다운 받은 후 $100 \times  100$ 으로 크기를 줄였다. 그리고 그 이미지를 앞서 소개한 세가지 방법으로 확대하였으며 결과는 아래와 같다.

```julia
img0= cv.resize(img2mat(testimage("lena_gray_256.tif")), cv.Size{Int32}(100, 100))
img1 = cv.resize(img0, cv.Size(Int32(256), Int32(256));interpolation= cv.INTER_NEAREST)
img2 = cv.resize(img0, cv.Size(Int32(256), Int32(256));interpolation= cv.INTER_LINEAR)
img3 = cv.resize(img0, cv.Size(Int32(256), Int32(256));interpolation= cv.INTER_CUBIC)
s = arr2mat(cat(img1, img2, img3; dims=2))
```


![왼쪽부터 최근접 이웃 보간, 이중 선형 보간, 이중 큐빅 보간](notebooks/interpolation.png)

</br>

## 공간적 이미지 필터링 {#sec-ImageProcessing_spatial_image_filtering}

공간적 필터링은 이미지를 2차원 공간으로 간주한다. 어떤 픽셀의 값을 그 주변값의 연산을 통해 바꿔서 원하는 목적을 달성하는 것을 공간적 이미지 필터링 이라고 한다. 많은 경우 2차원 배열을 사용하며 이 배열을 **커널(kernel)** 혹은 **마스크(mask)** 라고 한다. 즉 원본 이미지 $I$ 의 픽셀 $[i,\,j]$ 에 대해 부근의 픽셀의 집합 $A_[i,j]$ 을 사용하는 어떤 연산 $F$ 가 정의되어 연산된 이미지 $J$ 가 만들어 진다면, 즉

$$
J[i,j] = F\left(A_{[i,j]}\right)
$$

일 때 이 과정을 공간적 이미지 필터링 이라고 한다.

필터링 연산이 선형성을 갖는 경우를 이 필터에 의한 연산을 선형 필터라고 하며 대표적으로 평균값 필터와 가우시안 필터가 있다. 선형 필터가 아닌 필터를 비선형 필터라고 한다. 


<br>

### 가장저리 처리 {#sec-ImageProcessing_padding}

뒤에 나오겠지만 평균값 필터는 이미지의 어떤 픽셀과 그 주변의 선택된 픽셀값과의 평균으로 필셀값을 대체하는 필터이다. 예를 들어 이미지 $I$ 의 $[i, j]$ 픽셀 주위의 9개의 평균값으로 필터링 한다면

$$
J[i,\,j]=\frac{1}{9} \sum_{p=-1,\,0,\,1} \sum_{q=-1,\,0,\,1} I[i-p,\,j-q]
$$

일 것이다. 노이즈 처리에 사용 될 수 있다. 이 경우 가장자리 라면, 예를 들어 $i=0$ 이면 $i-1$ 픽셀이 없으므로 문제가 된다. 일반적으로 필터링의 범위를 고려하여 필터링에 방해가 되지 않도록 이미지의 크기를 일시적으로 키우고 원본 이미지에 없던 부분을 적당한 값으로 채운 후(이를 **패딩(padding)** 이라고 한다) 그 이미지 $\overline{I}$ 에 대해 필터링을 하고, 필터링된 이미지 $\overline{J}$ 를 원본 이미지에 맞게 크기를 줄이게 된다. 패딩을 할 때 특정한 값으로 채울 수도 있고(**상수 패딩(constant padding)**), 가장 가까운 원본 이미지 픽셀값을 복사할 수도 있으며(**복제 패딩(replication padding)**), 패딩되는 픽셀에 가장 가까운 원본 이미지 픽셀을 중심으로 대칭이 되도록 원본 픽셀 값을 복사할 수도 있다(**반사 패딩(reflection padding)**).

</br>

![이미지 패딩](imgs/padding.png){#fig-ImageProcessing_padding width=550}

</br>

이후로는 이미지 필터를 다룰 때 사용자가 적절한 패딩을 선택했다고 가정한다.

</br>


### 비선형 필터 (nonlinear filter)



- 중앙값 필터 (median filter) : 노이즈 처리에 좋다.

- 표준편차 필터(standard deviation filter) : 엣지 검출에 좋다.

</br>

<!-- 
### 가우시안 필터 (Gaussian filter)
$I[i,j]$ 를 필터링 할 때 주변 값과 정규분포 관계가 있다고 가정한다. 즉 멀수록 관계가 더 적다고 간주한다. 2차원 가우시안 함수는 다음과 같다.

$$
G(x,\,y | x',\,y') = \dfrac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\dfrac{(x-x')^2+(y-y')^2}{2\sigma^2}\right)
$$

$J[i,\,j]$ 는 $I[i,\,j]$ 를 중심으로 주변값에 2차원 가우시안 함수에 비례하는 가중치를 두고 그 평균을 계산한 값이 된다. 

python의 cv2 라이브러리에서는 다음과 같이 사용한다.

```python
filtered_image = cv2.GaussianBlur(original_image, (3, 3), 1.5)
```

여기서 `(3, 3)` 은 $3 \times 3$ 크기의 커널을 사용한다는 뜻이고 1.5 는 가우시안 분포의 표준편차이다.

</br> -->

## 합성곱 개념으로서의 이미지 필터링

### 합성곱과 상관값

::: {.callout-note appearance="simple" icon="false"}

::: {#def-ImageProcessing_convolution_and_correlation}

#### 합성곱과 상관값

원본 이미지 $I[i,\,j]$ 와 커널 $k[s,\,t]$ 을 생각하자. 이 때 커널은 $(2a+1)\times (2b+1)$ 크기의 2차원 배열이며 커널 배열의 인덱스는 

$$
\begin{aligned}
s:& -a,\, -(a-1),\ldots,\, -1,\,0,\,1,\ldots,\,a-1,\,a, \\
t:&-b,\, -(b-1),\ldots,\, -1,\,0,\,1,\ldots,\,b-1,\,b,
\end{aligned}
$$

로 잡는다. 이미지와 커널 사이의 **합성곱(convolution)** $k \ast I$ 와 **상관값(correlation)** $k \otimes I$ 는 각각 다음과 같이 정의된다. 

$$
\begin{aligned}
(k \ast I)[i, j] &:= \sum_{s=-a}^{a} \sum_{t=-b}^b k[s,\,t] \,I[i-s,\, j-t],\\[0.3em]
(k \otimes I)[i,j] &:= \sum_{s=-a}^{a} \sum_{t=-b}^b k[s,\,t]\, I[i+s,\, j+t].
\end{aligned}
$$ {#eq-ImageProcessing_definition_of_convolution_and_correlation}

:::

:::

</br>

우선 상관값을 살펴 보자. 커널이 

$$
k = \begin{bmatrix} 1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1\end{bmatrix}
$$

이고 원본 이미지의 $I[i, j]$ 를 중심으로 한 $3\times 3$ 배열이 

$$
\tilde{I}_{[i, j]}= I[i-1:i+1, j-1:j+1]= \begin{bmatrix} 4 & 0 & 2 \\ 1 & 0 & 3 \\ 2 & 3 & 1\end{bmatrix}
$$

이라면 $(k\otimes I)[i, j]$ 는 $k$ 와 $\tilde{I}_{[i, j]}$ 의 성분별 곱의 합으로 정의된다. 즉

$$
(k\otimes I)[i, j] = 1\times 4 + (-1)* 2 + 1 * 1 + (-1)\times 3 + 1 \times 2 + (-1)\times 1 = 1
$$

이다. 그러나 합성곱은 @eq-ImageProcessing_definition_of_convolution_and_correlation 에서 알 수 있듯이 $k$ 의 성분과 대각 위치에 있는 $\tilde{I}_{[i, j]}$ 의 성분의 모든 곱의 합이다. 즉,
$$
(k\otimes I)[i, j] = 1\times 2 + (-1)* 4 + 1 * 3 + (-1)\times 1 + 1 \times 1 + (-1)\times 2 = -1
$$

이다. 혹은 합성곱은 커널을 180 도 회전시킨 행렬과의 상관값이라고 생각 할 수도 있다. 또 커널과 합성곱의 중요한 차이는 아래 표와 같다.

| 성질 | 합성곱 | 상관값  |
|:-----:|:-------------:|:-------------:|
| commtative | $f\ast g = g \ast f$ | $-$ |
| associative | $f\ast(g \ast h) = (f \ast g)\ast h$ | $-$ |
| distributive | $f\ast(g+h)= f\ast g + f \ast h$ | $f\otimes (g + h) = f\otimes g + f \otimes h$| 
: 합성곱과 상관값의 수학적 성질 {#tbl-ImageProcessing_convolution_and_correlation}

</br>

일반적으로 상관값이 계산량이 적고 직관적인데 비해 합성곱이 수학적으로 좋은 성질을 많이 가지고 있다. 또한 커널이 중심에 대해 대칭이라면 합성곱과 상관값은 동일하다. 

</br>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#exm-ImageProcessing_convolution_and_correlation}

@def-ImageProcessing_convolution_and_correlation 의 커널 인덱스 표기법을 사용하자. 커널이 $k[-s,\,-t] = k[s,\,t]$ 라면 $k\ast I = k \otimes I$ 임을 보일 수 있다.

$$
\begin{aligned}
(k \ast I)[i,\,j] &= \sum_{s=-a}^{a} \sum_{t=-b}^b k[s,\,t] \,I[i-s,\, j-t] &&; s\to -s,\, t\to -t \\
&=\sum_{s=-a}^{a} \sum_{t=-b}^b k[-s,\, -t] I[i+s,\, j+t] &&;k[-s,\,-t] = k[s,\,t]\\
&= \sum_{s=-a}^{a} \sum_{t=-b}^b k[s,\, t] I[i+s,\, j+t] \\
&= (k\otimes I)[i, j]
\end{aligned}
$$

:::
</div>

</br>

가끔 합성곱과 상관값이 서로 혼용되기도 한다. 예를 들어 신경망의 합성곱 신경망(convolutional neural network, CNN) 에서는 실제로 이름에 나온 합성곱 연산이 아닌 상관 연산을 사용한다. 그러나 역사적, 관례적 이유로 합성곱 신경망이라는 이름을 사용한다.


</br>

## 빈도 필터

### 이미지에 있어 ‘빈도 (frequency)’
- 이미지에서 어떤 픽셀과 바로 이웃한 픽셀의 값이 매우 큰 차이를 보일 때 그 픽셀을 중심으로 픽셀 값의 ‘변화’는 매우 크다고 할 수 있다. 이렇게 픽셀 값의 변화가 매우 짧은 픽셀 간격에서 나타날 때, 그 픽셀은 <b>높은 주파수 성분</b>, 반대의 경우를 <b>낮은 주파수 성분</b>이라고 부른다.

<br>

#### 하이패스 필터 (high-pass filter), 로우패스 필터 (low-pass filter)
- 필터가 낮은 빈도를 나타내는 성분만 제거하거나 픽셀 값을 줄이는 기능을 갖는다면 하이패스 필터라 하고, 그 반대의 경우를 로우패스 필터라 한다.
- 사실 하이패스 필터는 이미지에서 가장자리 (엣지, edge)를 찾아 내거나 가장자리 신호를 선택적으로 강화하는 기능으로 자주 사용된다. 
- 앞서 살펴 본 평균값, 중간값, 가우시안 필터 등이 로우패스 필터이다. 

</br>

### Unsharp masking & highboost filtering

<br>

#### **Unsharp mask**
- 원본 이미지를 일단 평균값 필터링 같은 로우패스 필터로 블러링 (blurring) 처리한 후, 원본 이미지에서 처리된 이미지를 빼서 차이 값으로 이루어진 행렬을 ‘Unsharp mask’ 라 한다. 원본이미지를 $I[i,j]$, 블러링 된 이미지를 $\overline{I}[i,j]$ 라 하면 unsharp mask $M[i,j]$ 는 다음과 같다.

$$
M[i,j]=I[i,j]-\overline{I}[i,j]
$$

<br>

#### **Highboost filtering**
- 이 때 어떤 1보다 큰 양의 실수 $k$ 를 $M[i,j]$ 에 곱해서 원본에 더해준다면 가장자리신호가 더 현저해지며 이것을 highboost filtering 이라 한다. 즉

$$
J[i,j]=I[i,j]+k\,M[i,j] = I[i,j]+k(I[i,j]-\overline{I}[i,j])
$$

</br>

### Differential High-pass Filter

픽셀에 미분을 적용한다면 일단 간단하게 생각하면, $x$ 방향 편미분은 $\partial_x I [i,j]=I[i,j]-I[i-1,j]$ or $\partial_x I[i,j]=I[i+1,j]-I[i,j]$ 이며 $y$ 방향 편미분은 $\partial_y I[i,j]=I[i,j]-I[i,j-1]$ 혹은 $\partial_y I[i,j]=I[i,j+1]-I[i,j]$ 가 될 것이다. 

<br>

#### **로버츠 커널 (Roberts kernel)**

대각선 방향의 편미분에 해당하는 2차원 배열을 로버츠 마스크라 하며 아래와 같다.

$$
G_x = \begin{bmatrix} +1&0&0 \\ 0&-1&0 \\ 0&0&0 \end{bmatrix}, \quad G_y=\begin{bmatrix}0&+1&0\\-1&0&0\\0&0&0 \end{bmatrix}
$$

<br>

#### **Prewitt kernel**

$$
G_x = \begin{bmatrix}+1&0&-1\\+1&0&-1\\+1&0&-1\end{bmatrix}, \qquad 
G_y = \begin{bmatrix}+1&+1&+1\\0&0&0\\-1&-1&-1\end{bmatrix}
$$

<br>

#### **Sobel kernel**

$$
G_x = \begin{bmatrix}+1&0&-1\\+2&0&-2\\+1&0&-1\end{bmatrix},\qquad
G_y = \begin{bmatrix}+1&+2&+1\\0&0&0\\-1&-2&-1\end{bmatrix}
$$


</br>

### Laplaician filter

- 1차 미분 필터들은 한 번만 차분 값을 계산하기 때문에, 차 분의 크기도 작고, 이로 인해서 경계가 확실한 부분만 추출할 수 있는 반면, 노이즈가 있거나 엣지 (edge)의 강도가 약한 부분에는 불완전한 추출을 보이는 한계가 있다. 
- 이를 극복하기 위해 개발된 필터가 2차 미분형, 즉, 라플라시안 필터 (Laplacian filter) 이다. 라플라시안 필터는 말 그대로, 연속 함수 f(x,y)의 이계 도함수를 의미하는 라플라시안으로부터 유래한 것으로, 디지털 이미지에 대해, 아래와 같은 근사 공식을 활용하여 만들 수 있다.

$$
\begin{aligned}
\nabla^2 f &= \partial_x^2 f + \partial_y^2 f \\ 
\partial_x^2 I[i,j] & = I[i-1,j]+I[i+1,j]-2I[i,j] \\
\partial_y^2 I[i,j] & = I[i,j-1]+I[i,k+1]-2I[i,j] \\
\nabla^2 I[i,j] &= \partial_x^2 I[i,j]+ \partial_y^2 I[i,j] =I[i-1,j]+I[i+1,j]+I[i,j-1]+I[i,k+1]-4I[i,j]
\end{aligned}
$$


- 라플라시안 필터는, 앞서 살펴 본 1차 미분형 필터보다, 더 넓은 범위에서 그리고 모든 방향을 고려하여 차분 값을 계산할 수 있기 때문에, 경계선에서 픽셀 값이 변화하는 것 을 훨씬 강한 강도로 잡아낼 수 있으며, 이로 인해, 잡음에도 강하고, 엣지 정보를 더 잘 추출할 수 있다는 장점이 있다. 다만, 계산 시간은 1차 미분형 필터보다는 늘어나게 된다.


- Matlab 에서는 `fspecial(‘laplacian’,alpha)` 의 명령어로 laplacian kernel 을 만드는데 이는 보통의 laplacian kernel을 약간 수정한 것으로 다음과 같이 정의된다.
  $$
  \dfrac{1}{1+\alpha} \begin{bmatrix} \alpha & 1-\alpha & \alpha  \\ - \alpha & 4 & - \alpha \\ \alpha & 1-\alpha & \alpha\end{bmatrix}
  $$

  Matlab 에서는 $\alpha$ 값을 $[0,\,1)$ 에서 조정한다고 하는데, cv2 에서는 이러한 함수를 찾을 수 없어서 직접 만들어 사용하였다. 

</br>

### Laplacian of Gaussian Filter (LoG filter)

- 원본 이미지에 가우시안 블러링을 한 후 라플라시안 필터를 적용한다.

- 이 때 LoG filter 는 다음과 같은 꼴을 띈다.

$$
\nabla^2 \left( G_{\sigma} (x,\,y) \right) = \dfrac{x^2+y^2-2\sigma^2}{\sigma^4} \exp \left(- \dfrac{x^2+y^2}{2\sigma^2}\right)
$$

- 라플라시안 필터와 유사하게, LoG 필터도 이미지에서 엣지 부분의 정보를 효과적으로 추출할 수 있다. 특히, 라플라시안 필터보다 더 넓은 범위에서 이미지 합성 곱을 하기 때문에, 이미지 추출 과정에서 왜곡 가능성을 줄일 수 있다는 장점이 있다.

</br>

### 위너 필터 (Wiener filter)

원본 이미지 I 와 노이즈 처리된 이미지 J 사이의 차이를 통계적 관점에서 (혹은 확률적 관점에서) 정량화 하는 방법으로는 평균제곱편차 mean square error (MSE) 가 있다. MSE의 정의는 아래와 같다.

$$
\text{MSE} = \dfrac{1}{N} \sum_{i,\,j} \left[ I[i,\,j]-J[i,\,j]\right]^2
$$

위너 필터는 이러한 이미지 간 차이를 최소화하는 모든 종류의 비선형 필터를 의미한다. 

<br>

#### 위너 필터의 노이즈 감소 기능

- 원본 이미지 I에 노이즈 N 이 낀 이미지 I' 를 생각하자. 즉 다음과 같은 식을 생각하자.

$$
I'[i,j]=I[i,j]+N[i,j]
$$

- 노이즈의 경우 특별한 언급이 없으면 가우시안 노이즈를 생각한다. 그렇다면 노이즈의 평균은 $0$ 이 될 것이며 노이즈의 분산 $\sigma_N^2$ 는 $0$ 이 아닌 값을 갖는다. 어떤 픽셀을 중심으로 커널 배열을 덮어서 움직인다고 하자. 커널은 보통 원본 배열보다 아주 작기때문에 커널에 덮이는 영역의 평균은 $0$ 될 확률이 매우 낮으므로 그 평균값을 $m_{ij}$, 분산을 $\sigma^2_{ij}$ 라 하자. 이 때 해당 영역의 노이즈를 최소화하는 방식으로 노이즈를 처리하면 다음과 같은 관계식을 얻는다.

$$
J[i,j]=m_{ij} + \dfrac{\sigma^2_{ij}}{\sigma^2_{ij} + \sigma^2_N} {\big(} I[i,j]-m_{ij}{\big)}
$$

- 그런데 많은 경우 우리는 원본 이미지가 없이 노이즈가 낀 이미지만 있으므로 노이즈의 분산 $\sigma_N^2$ 를 모른다. 여기에 괜찮은 방법이 있는데, 그것은 바로 $\sigma_N^2$ 를 모든 로컬 분산 $\sigma_{ij}^2$ 의 평균으로 잡는 것이다. 

$$
\sigma_N^2 = \dfrac{1}{N} \sum_{i,j} \sigma^2_{i,j}
$$


#### 파이썬에서의 위너 필터

파이썬에서는 scipy 에서 wiener filter를 사용한다. Library refence 를 보면 대놓고 matlab의 wiener2 함수를 implementation 했다고 나온다. 사용법은 다음과 같다.

~~~python
from scipy.signal.signaltools import wiener

filtered_img = wiener(original_img, mysize=3)
~~~

여기서 mysize 는 kernel size 이다. 자세한 것은 library reference 참고. 이 때 주의할 것은 original_img 가 0 에서 255 사이의 정수값을 갖는, 보통 gray scale image 에서 많이 사용되는 uint8 형식의 정수형이면 안된다. 이 경우 다음과 같이 사용하는 것이 좋다.

~~~python
filtered_img = wiener(original_img.astype(np.float64), ksize)
~~~
