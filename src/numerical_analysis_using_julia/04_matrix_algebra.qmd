---
title: "Julia 에서의 행렬 계산"
# language: ../_language-ko_custom.yml 

number-sections: true
number-depth: 3
crossref:
  chapters: false
---


{{< include ../../latexmacros.qmd >}}

</br>


지금까지는 Julia 의 기본적인 벡터와 행렬, 그리고 연산을 이용하여 일반적인 행렬에 대한 가우스 소거법과 LU 분해, QR 분해를 구현하여 보았다. Julia 는 큰 벡터와 행렬을 다루기 위한 `SparseArrays` 모듈과 행렬 및 벡터 계산을 위한 `LinearAlgebra` 모듈을 기본으로 제공한다. 또한 다양한 형태의 행렬에 대한 특별한 연산도 제공한다. 이제 이런 기능들을 알아보도록 하자. 그 전에 벡터와 행렬의 크기 혹은 거리를 의미하는 노름을 먼저 알아보기로 하자.

</br>

## 벡터와 행렬의 노름과 조건수 {#sec-norm_of_vector_and_matrix}


### 벡터의 노름

[벡터의 노름(norm)](02_notations_and_propositions.qmd#def-innerproduct_space) 은 벡터의 크기에 대한 척도로서 실수, 혹은 복소수의 절대값과 비슷한 역할을 한다. 보통 $n$ 차원 유클리드 공간에서 사용하는 거리도 노름의 일종이다. 벡터공간에서의 노름은 특정한 성질을 만족하는 함수 가운데 선택된다. 내적벡터공간에서는 내적에 의해 자연스럽게 노름을 정의할 수 있지만 노름 자체는 집합에 부여되는 성질이며 내적과 관계 없이 노름을 정의할 수도 있다. 즉 어떤 집합에 위의 노름이 정의되면 노름공간이라고 한다. 
</br>

벡터의 노름에 대한 성질을 알기 위해 다음 부등식을 알 필요가 있다.


<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-norm_inequality}

#### 횔더부등식(Hölder's inequality) 과 민코프스키 부등식(Minkowski's ineqality)

$p\ge 1$ 이며 $1/p+1/q =1$ 일 때 다음이 성립한다.
$$
\begin{aligned}
\text{H\"older's inequality} & \sum_{i=1}^n |u_i v_i| \le \left(\sum_{i=1}^n |u_i|^p\right)^{1/p}\left(\sum_{i=1}^n |v_i|^q\right)^{1/q}, \\
\text{Mincowski's inequality} & \left(\sum_{i=1}^n |u_i+v_i|^p\right)^{1/p} \le \left(\sum_{i=1}^n |u_i|^p\right)^{1/p} + \left(\sum_{i=1}^n |v_i|^p\right)^{1/p}.
\end{aligned}
$$

:::

</div></br>

::: {.proof}

[수학적 증명](A_collection_of_proofs.qmd#sec-mathematical_proof) 의 [Hölder 부등식](A_collection_of_proofs.qmd#prp-hoelders_inequality) 를 참고하라.

:::


</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-p_morm}

#### $L_p$-노름 과 $\infty$-노름

$p>1$ 에 대해 아래와 같이 정의된 $\| \cdot \|_p : \R^n \to [0, \infty)$ 는 노름이며 이 노름을 $L_p$-노름 이라고 한다.

$$
\|\bf{v}\|_p := \left( \sum_{i=1} |v_i|^p \right)^{1/p}.
$$ 


::: 
:::

</br>

$p>1$ 인 실수에 대해 사용할 수 있으며 보통 $p=1,\,2,\,\infty$ 인 경우를 많이 사용한다. $p=1$ 인 경우는 맨해튼 노름(Manhattan norm) 혹은 taxicab norm 이라고 하며, 

$$
\|\bf{v}\|_1 = \sum_i |v_i|
$$

이다. $p=2$ 인 경우는 우리가 많이 사용하는 유클리드 노름(Euclidean norm) 으로

$$
\|\bf{v}\|_2 = \sqrt{\sum_i |v_i|^2} 
$$

이다. $p=\infty$ 인 경우는 상한 노름(maximum norm) 이라고 하며

$$
\|\bf{v}\|_{\infty} = \max_{i=1,\ldots} |x_i|
$$

이다. 혹은 단순히 $L_1,\,L_2,\,L_\infty$ 노름 이라고도 한다. 



</br>

다음은 쉽게 증명 할 수 있다.

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-p_norm}
$p=\infty$ 를 포함하여 $p \ge 1$ 일 때, 유한차원 벡터공간에서의 $L_p$-노름은 노름의 정의를 만족한다.
:::

</div>
</br>



::: {.callout-note icon="false" appearance="minimal" }
::: {#def-equivalence_of_norm}
#### 노름의 동등함

벡터공간 $V$ 에 두개의 노름 $\|\cdot \|_\alpha$ 와 $\|\cdot \|_\beta$ 가 정의되었을 때, 모든 $\bf{v}\in V$ 에 대해 어떤 상수 $c_1,\,c_2$ 가 존재하여 

$$
c_1 \|\bf{v}\|_\alpha \le \|\bf{v}\|_\beta \le c_2 \|\bf{v}\|_\alpha
$$

라면 이 두 노름을 **동등하다(equivalent)** 라고 한다. 유한차원 벡터공간에 대해서는 모든 노름이 동등하다는 것이 알려져 있다.
:::
:::

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-magnitude_of_Lp_norms}

$\bf{v}\in \mathcal{M}_n(\mathbb{F})$ 에 대해 다음이 성립한다. 즉 $\|\cdot \|_\infty$ 와 $\|\cdot \|_2$ 는 동등하다. 

$$
\|\bf{v}\|_{\infty} \le \|\bf{v}\|_2 \le \sqrt{n}\|\bf{v}\|_\infty
$$

:::

</div></br>

::: {.proof}

$v_M = \max \{ |v_i|, i=1,\ldots,\,v_n\}$ 이라고 하자. 
$$
\|\bf{v}\|_\infty = v_M \le \sqrt{\sum_{i=1}^n |v_i|^2} = \|\bf{v}\|_2 \le \sqrt{\sum_{i=1}^n {v_M}^2} = \sqrt{n} v_M = \sqrt{n} \|\bf{v}\|_\infty
$$

이다. $\square$ 
:::

</br>

Julia 에서는 `LinearAlgebra` 모듈의 `norm(v, p=2)` 로 정의되는 함수를 이용하여 계산 할 수 있으며 `p` 는 `1`, `2`, `Inf` 가 가능한데 각각 $L_1,\,L_2,\,L_\infty$ 노름을 의미한다. 노름이 정의된 벡터공간에서 벡터를 그 크기로 나누는 것 ($\bf{v}/\|\bf{v}\|$) 을 정규화(normalization) 라고 하며 역시 `LinearAlgebra` 모듈에 `normalize(v, p=2)` 함수로 구현되어 있다. [`norm(v, p=2)` 에서 `p=2` 는 `p` 의 기본값이 `2` 라는 의미이다. 즉, `norm(v)` 로 벡터만을 인자로 하여 함수를 호출했을 경우는 `p=2` 일 경우를 계산한다.]{.aside}


```txt
In [1]: using LinearAlgebra

In [2]: v=[1, 2, 3];

In [3]: norm(v, 1)
Out[3]: 6.0

In [4]: norm(v, Inf)
Out[4]: 3.0

In [5]: norm(v, 2)
Out[5]: 3.7416573867739413

In [6]: normalize(v)
Out[6]: 3-element Vector{Float64}:
 0.2672612419124244
 0.5345224838248488
```

</br>

### 행렬의 노름 {#sec-norm_of_matrix}

행렬의 노름(norm) 역시 행렬의 크기에 대한 척도로서 특정한 성질을 만족하는 함수 가운데 선택된다.

::: {.callout-note appearance="simple" icon="false"}
::: {#def-matrix_norm}

행렬의 노름 $\|\cdot \|: \mathbb{F}^{n\times n} \to \mathbb{R}$ 은 행렬 $\bf{A},\, \bf{B}$ 와 스칼라 $\alpha$ 에 대해 다음의 성질을 만족한다.

&emsp; ($1$) $\|\bf{A}\| \ge 0$, 

&emsp; ($2$) $\|\bf{A}\| = 0 \iff \bf{A} = 0$, 

&emsp; ($3$) $\|\alpha \bf{A}\| = |\alpha| \|\bf{A}\|$, 

&emsp; ($4$) $\|\bf{A}+\bf{B}\| \le \|\bf{A}\|+\|\bf{B}\|$.

또한 $\bf{A}\in \mathbb{F}^{m\times n},\, \bf{B} \in \mathbb{F}^{n\times p}$ 에 대해 다음이 성립한다.

&emsp; ($5$) $\|\bf{AB}\| \le \|\bf{A}\| \cdot\|\bf{B}\|$.

:::
:::

</br>

위의 정의 중 5번을 제외한 나머지 성질은 벡터에 대해서 성립하며, 5번은 행렬의 노름에만 성립하는 고유한 성질이다.

</br>

#### **프로베니우스 노름**

[프로베니우스 노름은 힐버트-슈미트 노름(Hilbert-Schmidt norm), 혹은 슈어 노름(Schur norm) 으로도 불린다.]{.aside}

선형대수학에서 배웠다시피 $\mathbb{F}^{m\times n}$ 은 벡터공간을 이루며 각각의 $\bf{A}\in \mathbb{F}^{m\times n}$ 도 벡터므로, 벡터에 대한 노름 처럼 행렬에 대한 노름도 정의 할 수 있다. 대표적으로 프로베니우스 노름(Frobenius norm) $\|\cdot \|_F$ 은 행렬을 벡터처럼 간주했을 때의 $L_2$ 노름이다.

::: {.callout-note appearance="simple" icon="false"}
::: {#def-frobenius_norm}

#### 프로베니우스 노름
$m \times n$ 행렬에 대한 프로베니우스 노름(Frobenius norm) 은 다음과 같이 정의된다.
$$
\|\bf{A}\|_F := \left(\sum_{i=1}^m \sum_{j=1}^n |A_{ij}|^2\right)^{1/2} = \sqrt{\text{tr}(\bf{AA}^\dagger)}
$$

:::
:::

</br>
<div class="border" style="background-color:#F0FFFF  ;padding:5px;">

::: {#exr-frobenius_norm}
프로베니우스 노름이 행렬의 노름의 정의에 나열된 5가지의 성질을 만족한다는 것을 보여라.
:::

</div>

</br>

#### **자연스러운 노름** {#sec-natural_norm}

행렬은 벡터공간에서 정의된 선형 함수로서의 의미가 중요하기 때문에, 벡터가 연산되었을 때 그 크기가 어떻게 되는지에 관심이 있는 경우가 많다. 이런 의미에서 행렬의 노름을 벡터와의 연산에 대해 정의할 수 있는데 이렇게 정의된 행렬의 노름은 **유도된 행렬 노름 (induced matrix norm)**, **자연스러운 행렬 노름(natural matrix norm)** 혹은 **종속된 노름(subordinate norm)** 이라고 하며 정사각 행렬의 경우는 **연산자 노름(operator norm)** 이라고도 한다. <u>앞으로 행렬의 노름을 이야기할 때는 별다른 언급이 없다면 자연스러운 노름을 의미한다.</u>

</br>

::: {.callout-note appearance="simple" icon="false"}
::: {#def-operator_norm}

#### 행렬의 노름

$\mathbb{F}^n$ 에서의 노름이 $\|\cdot \|_\alpha$, $\mathbb{F}^m$ 에서의 노름이 $\| \cdot \|_\beta$ 로 정의되었다고 하자. $\bf{A}\in \mathbb{F}^{m \times n}$ 에 대한 연산자 노름은 다음과 같이 정의된다.

$$
\|\bf{A}\|_{\alpha,\,\beta} := \sup \{\|\bf{Av}\|_\beta : \|\bf{v}\|_\alpha=1\} = \sup_{\|\bf{v}\|_\alpha = 1} \|\bf{Av}\|_\beta
$$

위의 정의와 다음의 정의는 같다.
$$
\|\bf{A}\|_{\alpha,\,\beta} = \sup \left\{\dfrac{\|\bf{Av}\|_\beta}{\|\bf{v}\|_\alpha} : \bf{v}\in \mathbb{F}^n,\, \bf{v}\ne \bf{0} \right\} = \sup_{\|\bf{v}\|_\alpha \ne 0}\dfrac{\|\bf{Av}\|_\beta}{\|\bf{v}\|_\alpha}.
$$

:::
:::

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-operator_norm}
자연스러운 노름은 행렬의 노름의 정의에 나열된 5 가지 성질을 만족한다.
:::

</div></br>

::: {.proof}
$1$, $2$, $3$, $4$는 쉽게 보일 수 있다. 각각의 벡터공간에서 노름을 상징하는 아래첨자는 생략해도 이해하는데 무리가 없을 것이다.

$\text{5}$. 우선 $\|\bf{Av}\| \le \|\bf{A}\| \cdot \|\bf{v}\|$ 임을 보이자. $\bf{v}=\bf{0}$ 일 때는 자명하다. $\bf{v}\ne \bf{0}$ 이라면,

$$
\|\bf{A}\| = \sup_{\|\bf{v}\|\ne 0} \left\{ \dfrac{\|\bf{Av}\|}{\|\bf{v}\|} \right\} \ge \dfrac{\|\bf{Av}\|}{\|\bf{v}\|}
$$

이므로 $\|\bf{Av}\| \le \|\bf{A}\|\cdot \|\bf{v}\|$ 이다. 이를 이용하면
$$
\|\bf{ABv}\| \le \|\bf{A}\| \cdot \|\bf{Bv}\| \le \| \bf{A}\| \cdot \|\bf{B}\| \cdot \|\bf{v}\|
$$

이므로 $\dfrac{\|\bf{ABv}\|}{\|\bf{v}\|} \le \|\bf{A}\|\|\bf{B}\|$ 이다. 따라서,

$$
\|\bf{AB}\| =\sup \left\{ \dfrac{\|\bf{ABv}\|}{\|\bf{v}\|}\right\} \le \|\bf{A}\| \|\bf{B}\|
$$

이다. $\square$
:::

</br>

다음은 증명 과정에서 보였지만 별도로 언급할 가치가 있다.

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#cor-norm_of_matrix_and_vector}

$\|\bf{Av}\|\le \|\bf{A}\|\cdot \|\bf{v}\|$ 이다.

:::

</div></br>

이것이 의미하는 것은 행렬 $\bf{A}$ 의 노름은 $\bf{A}$ 에 의해 변환되는 벡터의 노름이 변화하는 최대값을 규정한다는 것으로, 앞으로 매우 많이 나올 내용이다.



행렬의 정의역(domain)과 공역(codomain)에서의 노름이 동일할 때 $\|\bf{A}\|_\alpha$ 와 같이 노름에 대한 첨자를 하나만 표기한다. 또한 노름을 계산할 때 $L_p$ 벡터 노름, 그중에서도 $p=1, 2, \infty$ 를 많이 사용한다. 즉

$$
\|\bf{A}\|_p = \sup \left\{ \dfrac{\|\bf{Av}\|_p}{\|\bf{v}\|_p}\right\}
$$

이다. 


</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-special_matrix_norm}
$\bf{A}\in \mathbb{F}^{m \times n}$ 일 때,
$$
\begin{aligned}
\|\bf{A}\|_\infty &= \max_{i=1,\ldots,\,m} \sum_{j=1}^n |A_{ij}|,\\
\|\bf{A}\|_1 &= \max_{j=1,\ldots,\,n} \sum_{i=1}^m |A_{ij}|,\\
\end{aligned}
$$

이다.
:::

</div></br>

::: {.proof}

벡터 $L_p$-노름의 정의로부터,
$$
\|\bf{Av}\|_\infty = \sup \left\{ \left|\sum_{j=1}^n A_{ij}v_j\right| : i=1,\ldots,\,m,\, \|\bf{v}\|_\infty = 1 \right\}
$$
이다. $\|\bf{v}\|_\infty=1$ 이면 $|v_j|\le 1,\, i=1,\ldots,\,n$ 이므로
$$
\left| \sum_{j=1}^n A_{ij}v_j\right| \le \sum_{j=1}^n |A_{ij}|\cdot |v_j| \le \sum_{j=1}^n |A_{ij}|
$$
인데 $v_j = \text{sign}(A_{ij})$ 일 때 등호가 성립한다. 따라서, $\displaystyle \|\bf{A}\|_\infty = \max_{i=1,\ldots,\,m} \sum_{j=1}^n |A_{ij}|$ 이다. 

$\|\bf{A}\|_1 = \displaystyle \sup_{\|\bf{v}\|_1=1} \|\bf{Av}\|_1$ 이며, $\displaystyle \|\bf{v}\|_1 = \sum_{j=1}^n |v_j|$ 이다.

$$
\begin{aligned}
\|\bf{Av}\|_1 &= \sum_{i=1}^m \left| \sum_{j=1}^n A_{ij}v_j\right| \le \sum_{i=1}^m \sum_{j=1}^n |A_{ij}| \cdot |v_j| = \sum_{j=1}^n |v_j| \left(\sum_{i=1}^n |A_{ij}|\right) \\
&\le \max_{j=1,\ldots,n} \left(\sum_{i=1}^n |A_{ij}|\right) \\
\end{aligned}
$$

이다. $\displaystyle \sum_{i=1}^n |A_{ij}|$  이 최대가 되는 $j$ 인덱스를 찾아 $j_M$ 이라 하면

$$
\|\bf{Ae}_{j_M}\|_1 = \sum_{i=1}^m |A_{i,j_M}| = \max_{j=1,\ldots,n} \sum_{i=1}^m |A_{ij}|
$$

이다. 따라서 $\displaystyle \|\bf{A}\|_1 = \max_{j=1,\ldots,\,n}\sum_{i=1}^m |A_{ij}|$ 이다. $\square$

:::

</br>



Julia 에서 행렬의 $L_p$ 노름은 `opnorm(A, p=2)` 로 구현되었으며 가능한 `p` 값은 `1`, `2` 와 `Inf` 로 각각 $L_1,\, L_2,\,L_\infty$ norm을 계산한다. Frobenius 노름은 `norm(A, 2)` 로 벡터의 `norm` 처럼 계산 할 수 있다.

```txt
In [7]: A = [1 3 2; 4.0 2.0 -3.0];

In [8]: opnorm(A, 1), opnorm(A, 2), opnorm(A, Inf)
Out[8]: (5.0, 5.47722557505166, 9.0)

In [9]: norm(A, 2) # Frobenius norm
Out[9]: 6.557438524302
```

</br>

### 행렬의 조건수 {#sec-condition_number_of_matrix}

어떤 함수 $f$ 와 이를 구현하여 수치해석적으로 계산하는 함수 $\overline{f}$ 가 있다고 하자. 많은 경우 $f(x)$ 와 $\overline{f}(x)$ 는 차이가 나며 이 차이를 계량하기 위애 보통 아래의 세가지 오차를 사용한다.


::: {.callout-note appearance="minimal"}

::: {#def-errors}

#### 오차, 절대오차, 상대오차

함수 $f(x)$ 와 그 수치해석적인 구현 $\overline{f}(x)$ 에 대해 아래와 같은 세가지 오차를 정의 할 수 있다.

&emsp; ($1$) **오차(error)** $\delta f(x) := f(x) - \overline{f}(x)$.

&emsp; ($2$) **절대오차(absolute error)**  $|\delta f(x)| := |f(x) - \overline{f}(x)|$.

&emsp; ($3$) **상대오차(relative error)** $\displaystyle \dfrac{|\delta f(x)|}{|f(x)|} = \dfrac{|f(x) - \overline{f}(x)|}{|f(x)|}$.

:::

:::

</br>

위의 세가지 오차는 우리가 구하고자 하는 $f$ 와 우리가 고안한 $\overline{f}$ 사이의 차이에 대해 정량화 한 값이다. 이제 시스템 자체의 안정성에 대해 한번 보기로 하자. 시스템을 기술하는 함수 $f(x)$ 가 있다고 하자. 적당하게 작은 $\delta x$ 애 대해 만약 $f(x_0+\delta x)$ 가 $f(x_0)$ 와 큰 차이가 난다면 이 시스템을 다루는 데는 큰 주의가 필요할 것이다. 이를 **ill-conditioned** 라고 한다. 반대로 $f(x_0 + \delta x)$ 가 $f(x)$ 와 큰 차이가 나지 않는다면 $x_0$ 에 어느 정도 오차가 있더라도 우리가 구하고자 하는 값과 큰 차이가 나지 않을 것이고 우리가 다루기 쉬울 것이다. 이를 **well-conditioned** 라고 한다. 이 성질의 정량화를 위해 함수 $f$ 에 대한 조건수를 아래와 같이 정의한다.

</br>

::: {.callout-note appearance="minimal"}

::: {#def-condition_number_of_function}

#### 함수의 조건수

함수 $f:X\subset \mathbb{R}^m \to \mathbb{R}^n$ 와 $x_0 \in X$ 에 대해 아래와 같이 정의된 $\kappa_f (x_0)$ 를 $f$ 의 $x_0 (\ne \bf{0})$ 에 대한 **조건수 (condition number)** 혹은 **상대적 조건수 (relative condition number)** 라고 한다.

$$
\kappa_f(x_0) = \lim_{\epsilon \to 0} \sup_{\|\delta x\| < \epsilon} \dfrac{\|f(x_0+\delta x)-f(x_0)\|/\|f(x_0)\|}{\|\delta x\|/\|x_0\|}
$$

:::

:::

</br>

$\kappa_f(x_0) \ll 1$ 이라면 $\|f(x_0 + \delta x)\|$ 가 $\|f(x_0)\|$ 와의 차이가 매우 작다. 즉 well-conditioned 이다. 반대로 $\kappa_f(x_0) \gg 1$ 이라면 $\|f(x_0+\delta x)\|$ 가 $\|f(x_0)\|$ 와의 차이가 매우 크기때문에 ill-conditioned 이다. 

</br>

다음은 미분의 정의로부터 쉽게 보일 수 있다.

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-condition_number_for_differential_function}

$F:\mathbb{R}^m \to \mathbb{R}^n$ 가 미분가능한 함수라면

$$
\kappa_F(\bf{x}_0) = \dfrac{\|DF(\bf{x}_0) \| \cdot \|\bf{x}_0\|}{\|F(\bf{x}_0)\|}
$$

이다.

:::

</div>
</br>

가역행렬인 정사각 행렬 $\bf{A}\in \mathbb{R}^{n \times n}$ 을 생각하자. $\bf{A}$ 는 $\mathbb{R}^n \mapsto \mathbb{R}^n$ 함수이므로 조건수를 생각 할 수 있다. $\bf{Ax}_0 = \bf{y}_0$ 라고 하면 $\bf{x}_0 = \bf{A}^{-1}\bf{y}_0$ 이므로, 

$$
\dfrac{\|\bf{A}(\bf{x}_0 + \delta \bf{x}) - \bf{Ax}_0\|/\|\bf{Ax}_0\|}{\|\delta\bf{ \bf{x}}\|/\|\bf{x}_0\|} = \dfrac{\|\bf{A}\delta \bf{x}\|}{\|\delta \bf{x}\|} \dfrac{\|\bf{x}_0\|}{\|\bf{Ax}_0\|} =  \dfrac{\|\bf{A}\delta \bf{x}\|}{\|\delta \bf{x}\|} \dfrac{\|\bf{A}^{-1}\bf{y}_0\|}{\|\bf{y}_0\|} \le \|\bf{A}\| \cdot \|\bf{A}^{-1}\|
$$

이다. 또한 @def-matrix_norm 의 ($5$) 로 부터, 

$$
\|\bf{A}\|\cdot\|\bf{A}^{-1}\| \ge \|\bf{AA}^{-1}\| = 1
$$

이 성립한다. 즉 가역행렬의 경우 조건수는 함수에 대한 입력값($\bf{x}_0$) 과는 상관 없이 행렬과 그 역행렬의 노름의 곱으로 정해진다. 

::: {.callout-note appearance="minimal"}

::: {#def-conditional_number_of_invirtible_matrix}

#### 가역행렬의 조건수

$n \times n$ 가역행렬 $\bf{A}$ 에 대해 조건수 $\kappa_\bf{A}$ 는 다음과 같다.

$$
\kappa_\bf{A} := \|\bf{A}\| \cdot \|\bf{A}^{-1}\|
$$

:::

:::

</br>
<div class="border" style="background-color:#FFF0F5 ;padding:5px;">

::: {#prp-condition_number_for_types_of_matrix}

$\bf{A}\in \mathbb{F}^{n \times n}$ 가 정규행렬이며 $\mathbb{F}^n$ 에 대해 $L_2$ 노름이 정의되어 있다고 하자. $\bf{A}$ 의 고유값의 집합 $\Lambda$ 에 대해 $\lambda_\max := \max \{|\lambda|: \lambda \in \Lambda\}$, $\lambda_\min := \min \{|\lambda| :\lambda \in \Lambda \}$ 일 때 다음이 성립한다.

$$
\kappa_\bf{A}= \dfrac{\lambda_{\max}}{\lambda_{\min}}
$$ 

:::

</div></br>

::: {.proof}

$\bf{A}$ 가 정규행렬이면 고유벡터로 대각화가 가능하며, 가역이므로 고유값은 모두 $0$ 이 아니다. 이제 $\bf{A}$ 를 각각의 대각성분이 모두 $0$ 이 아닌 대각행렬로 간주해도 된다. $\bf{v}\in \mathbb{F}^n$ 가 정규화된 벡터라고 하면

$$
\|\bf{Av}\|_2  \le |\lambda_\max|
$$

이다. $\bf{v}$ 가 $\lambda_\max$ 에 대한 고유벡터일 때 등호가 성립하므로 $\|\bf{A}\|_2 = \lambda_\max$ 이다. 같은 방법으로 $\|\bf{A}^{-1}\|_2 = \dfrac{1}{\lambda_\min}$ 임을 보일 수 있다. $\square$

:::

</br>

<div class="border" style="background-color:#FFF0F5 ;padding:5px;">
::: {#cor-condition_number_for_types_of_matrix}

$\bf{A}\in \mathbb{F}^{n \times n}$ 가 에르미트 행렬일 때도 @prp-condition_number_for_types_of_matrix 가 성립한다.

:::
</div>
</br>

## 다양한 행렬들

여기서는 julia 언어에서 다양한 벡터와 행렬을 어떻게 다루는 지를 배운다. 

</br>

### 성긴행렬과 밀집행렬 {#sec-sparse_matrix}

수학적으로 **희소행렬**(혹은 **성긴행렬**, **sparse matrix**) 은 행렬 성분의 대다수가 0 인 행렬을 의미하며, 반대의 경우를 **밀집 행렬(dense matrix)** 이라고 한다. 우리가 지금까지 다룬 행렬들은 행렬의 모든 성분을 컴퓨터가 저장하였다. 그러나 행렬이 매우 큰 경우, 예를 들면 `Float64` 타입의 $100K \times 100K$($1K=1,000$) 행렬은 성분을 저장하는 데만 80 Gbytes 의 저장공간을 차지하므로 개인 컴퓨터에서는 처리가 거의 불가능하며, 실제로 많이 다루는 시스템은 이것보다 훨씬 클 수 가 있다. 다행히 우리가 관심있는 시스템 가운데 상당수는 행렬의 대부분의 성분이 $0$ 인데, 이 경우 행렬의 모든 성분을 저장하는 것이 아니라 $0$ 이 아닌 성분만을 그 인덱스와 함께 저장하여 더 작은 저장공간에서 더 빠르게 계산 할 수 있다. 수치해석에서는 이렇게 행렬의 인덱스와 값을 저장하고, 인덱스가 지정되지 않은 행렬을 $0$ 으로 간주하는 행렬을 희소 행렬이라 하며, 우리가 지금 까지 다뤘던, 인덱스에 따라 순차적으로 성분을 저장하는 행렬을 밀집 행렬 (dense matrix) 이라 한다.

다차원 배열에 대해서도 희소배열을 생각 할 수 있으며 Julia 의 표준 라이브러리에 포함된 `SparseArrays` 모듈을 이용하여 1차원 배열인 희소벡터와, 2차원 배열인 희소행렬을 지원한다. Julia 에서의 희소행렬은 내부적으로 아래와 같이 구현되어 있다. 5개의 멤버를 갖는 구조체이며 행렬의 크기와, 행, 열, 값을 갖는다. `SmarseMatrixCSC` 의 `CSC` 는 희소행렬을 내부적으로 저장할 때 쓰는 일종의 압축 방식을 표현한다.

```julia
struct SparseMatrixCSC{Tv,Ti<:Integer} <: AbstractSparseMatrixCSC{Tv,Ti}
    m::Int                  # Number of rows
    n::Int                  # Number of columns
    colptr::Vector{Ti}      # Column j is in colptr[j]:(colptr[j+1]-1)
    rowval::Vector{Ti}      # Row indices of stored values
    nzval::Vector{Tv}       # Stored values, typically nonzeros
end
```

가장 기본적인 생성 방법은 `sparse()` 함수를 이용하는 것이다. 아래의 예에서 `A` 는 밀집행렬이며 이것을 `sparse` 함수를 통해 희소행렬로 만들었다. 혹은 `sparse(I, J, V)` 를 통해서도 생성할 수 있는데, `I` 는 행 인덱스를 나타내는 벡터, `J` 는 열 인덱스를 나타내는 벡터, `V` 는 값을 나타내는 벡터이다. 즉, `B=sparse(I, J, V)` 라면,

$$
B_{I[i], J[i]}=V[i], \, i=1,\,2,\ldots
$$

이다.


```txt
In [1]: using LinearAlgebra, SparseArrays

In [2]: A = Matrix(1.0I, 3, 3)
Out[2]: 3×3 Matrix{Float64}:
 1.0  0.0  0.0
 0.0  1.0  0.0
 0.0  0.0  1.0

In [3]: sparse(A)
Out[3]: 3×3 SparseMatrixCSC{Float64, Int64} with 3 stored entries:
 1.0   ⋅    ⋅ 
  ⋅   1.0   ⋅ 
  ⋅    ⋅   1.0

In [4]: B = sparse([1, 1, 2, 3], [1, 3, 2, 3], [-1.0, 2.0, 0.0, 4.0])
Out[4]: 3×3 SparseMatrixCSC{Float64, Int64} with 4 stored entries:
 -1.0   ⋅   2.0
   ⋅   0.0   ⋅ 
   ⋅    ⋅   4.0

In [5]: dropzeros(B)
Out[5]: 3×3 SparseMatrixCSC{Float64, Int64} with 3 stored entries:
 -1.0   ⋅   2.0
   ⋅    ⋅    ⋅ 
   ⋅    ⋅   4.0
```

마지막의 `dropzeros()` 함수는 희소 행렬 내의 $0$ 을 제거하여 저장공간을 줄인다. `B=sparse(I, J, V)` 형식으로 생성하면, `B` 행렬의 크기는 `I` 와 `J` 벡터의 최대값으로 정해지지만, 행렬의 크기를 정할 수 있다. 예를 들어, 

```txt
In [6]: sparse([1, 2], [1, 3], [1, -1], 4, 4)
Out[6]: 4×4 SparseMatrixCSC{Int64, Int64} with 2 stored entries:
 1  ⋅   ⋅  ⋅
 ⋅  ⋅  -1  ⋅
 ⋅  ⋅   ⋅  ⋅
```

와 같이 `sparse(I, J, V, m, n)` 형식으로 생성하면 이 희소행렬은 $m \times n$ 행렬이 된다. 희소벡터는 `sparsevec(I, V, m)` 형식으로 생성 할 수 있다.

```txt
In [7]: sparsevec([1, 4], [2, -1], 5)
Out[7]: 5-element SparseVector{Int64, Int64} with 2 stored entries:
  [1]  =  2
  [4]  =  -1
```

영행렬 혹은 영벡터는 `spzeros()` 함수를 통해 생성한다. 성긴 단위행렬은 `sparse(I, 4, 4)` 와 같이 생성한다. 단 `I` 는 `LinearAlgebra` 모듈에 정의되어 있으므로 `using LinearAlgebra` 를 한 후 사용할 수 있다.

```julia
using LinearAlgebra, SparseArrays
sm1 = spzeros(Float32, 10, 10) # Float32 타입의 값을 갖는 10x10 성긴행렬
sm2 = spzeros(5, 5) # 타입이 지정되지 않으면 Float64 타입의 값을 갖는다.
sv = spzeros(4) #Float64 타입의 4 차원 벡터
sI = sparse(I, 4, 4) # 4xt 단위행렬
```

</br>

### 타입으로 정의된 행렬 

`LinearAlgebra.jl` 은 선형대수학에서 사용되는 특별한 명칭이 붙은 행렬중 일부를 특별히 별도의 타입으로 지정하였다. 아주 단순한 예를 들자면 선형 시스템 $\bf{Ax}=\bf{b}$ 를 풀 때, $\bf{A}$ 가 대각성분을 제외한 성분이 모두 $0$ 인 대각행렬이라면 쉽게 풀 수 있으며, 상삼각행렬이나, 하삼각행렬이라도 일반적인 행렬에 비해서도 훨씬 쉽게 풀 수 있다. 그러나 컴퓨터가 임의로 $\bf{A}$ 가 어떤 행렬인지 결정하게 하기는 힘들며, 때때로 바람직 하지 않은 오류를 낼 수 있다. Julia 에서는 다중 디스패치를 이용할 수 있으므로 행렬 $\bf{A}$ 를 각각의 형태에 맞는 타입으로(대각행렬이라든가, 상삼각행렬이라든가) 정해 줄 수 있다면 이에 맞춰서 선형 시스템을 푸는 함수를 공통적으로 정의 할 수 있다. 즉 `solve_linearsystem_diagonal`, `solve_linearsystem_uppertriangula` 등을 따로 정의 할 필요 없이 `solve_linearsystem(A::Diatonal)`, `solve_linearsystem(A::UpperTriangula)` 와 같이 할 수 있다는 뜻이다.

`LinearAlgebra.jl` 에 정의된 특수한 타입으로서의 행렬의 목록은 아래와 같다.

::: {.callout-warning}
아래의 목록에 정의된 행렬의 타입들 가운데 상당수는 희소행렬이다. 굳이 밀집행렬로 바꾸고 싶다면 `Matrix(A)` 를 사용한다.
:::

</br>

| 타입 | 명칭 | 설명 |
|:---------:|:----------|:-------:|
| `UniformScaling` | Uniform scaling operator | c$\bf{I}$|
| `Diagonal` | 대각행렬 (Diagonal matrix) | 
| `Bidiagonal` | 상/하 쌍대각 행렬 (Upper/lower bidiagonal matrix) |
| `Tridiagonal` | 삼중 대각 행렬 (Tridiagonal matrix) |
| `SymTridiagonal` | 대칭 삼중 대각 행렬 (Symmetric tridiagonal matrix) |
| `UpperTriangular` | 상삼각행렬 (Upper triangular matrix) | $i>j \implies A_{ij}=0$
| `UnitUpperTriangular` | 단위 상삼각행렬 (Upper triangular matrix with unit diagonal) | 상삼각행렬이며 대각성분이 $1$ |
| `LowerTriangular` | 하삼각행렬 (Lower triangular matrix) | $i<j \implies A_{ij}=0$ |
| `UnitLowerTriangular` | 단위 하삼각행렬 (Lower triangular matrix with unit diagonal) | 하삼각행렬이며 대각성분이 $1$ |
| `UpperHessenberg` | 상 헤센베르크 행렬 (Upper Hessenberg matrix) |
| `Symmetric` | 대칭 행렬 (Symmetric matrix) | $\bf{A} =\bf{A}^T$ |
| `Hermitian` | 에르미트 행렬 (Hermitian matrix) | $\bf{A} =\bf{A}^\ast$ |

</br>

#### `UniformScaling`

`UniformScaling` 은 단위행렬에 상수를 곱한것을 말한다. `UniformScaling(2.0)` 은 (`2.0` 이 `Float64` 타입의 부동소수이므로) `Float64` 타입의 성분을 갖는 단위행렬이다. 다만 아직까지는 차원이 정해지지 않으며 다른 행렬과 연산될 때 적절한 차원을 갖게 된다. 단위행렬을 나타내는 `I` 를 대신 사용 할 수 있으며, `UniformScaling(2.0)==2.0I` 이다.

```txt
In [1]: using LinearAlgebra, SparseArrays

In [2]: 2.0I + 3
Out[2]: 5.0

In [3]: 2.0I + [0  1; 2 3]
Out[3]: 2×2 Matrix{Float64}:
 2.0  1.0
 2.0  5.0
```

</br>

#### `Diagonal` {#sec-diagonal_matrix}

대각행렬을 나타내는 타입이다. $n$ 차원 벡터를 입력하면 차례로 대각성분이 되는 대각행렬을 만든다.

```txt
In [4]: Diagonal([1, 10, 100])
Out[4]: 3×3 Diagonal{Int64, Vector{Int64}}:
 1   ⋅    ⋅
 ⋅  10    ⋅
 ⋅   ⋅  100
```

`Diagonal` 타입의 행렬에 `UniformScaling` 을 더하면, 아마 여러분이 예상한 결과가 나올 것이다.

```julia
In [5]: Diagonal([1, 10, 100]) + 3.0I
Out[5]: 3×3 Diagonal{Float64, Vector{Float64}}:
 4.0    ⋅      ⋅ 
  ⋅   13.0     ⋅ 
  ⋅     ⋅   103.0
```

</br>

#### `Bidiagonal`, `Tridiagonal`, `SymTridiagonal` {#sec-pseudodiagonal_matrix}

$m\times n$ 행렬 $A_{ij}$ 에서 $A_{ii},\, i=1,\ldots,\, \min \{m,\,n\}$ 을 대각(diagonal) 성분이라 한다. 대각 성분의 바로 오른쪽 성분, 즉 $A_{i,\, i+1}$ 을 **상대각 (superdialgonal)** 성분이라 하며, 왼쪽 성분, 즉 $A_{i+1,\,i}$ 을 **하대각(subdiagonal)** 성분이라 한다.(적절한 번역어를 못찾아서 임의로 붙인 이름이다.)

대각행렬과 대각성분 근처의 일부만을 제외한 모든 성분이 $0$ 인 행렬을 **띠행렬 (Band matrix)**이라 한다. 대각성분과 상대각 성분/하대각 성성분 가운데 하나를 제외한 모든 성분이 $0$ 인 행렬을 각각 상쌍대각 행렬/하쌍대각 행렬이라 한다. 아래의 보기에서 $\bf{B}_U$ 는 상쌍대각행렬, $\bf{B}_L$ 은 하쌍대각행렬이다.

$$
\bf{B}_U = \begin{bmatrix} 4 & 1 & 0 &0  \\ 0 & 3 & 1 & 0 \\ 0 & 0 & 2 &  2 \\ 0 & 0 & 0 & 5 \end{bmatrix} ,\qquad \bf{B}_L = \begin{bmatrix} 4 & 0 & 0 &0  \\ 1 & 3 & 0 & 0 \\ 0 & 1 & 2 &  0 \\ 0 & 0 & 2 & 5 \end{bmatrix}
$$

쌍대각 행렬은 `Bidiagonal` 객체로 표현되며, 두가지 방법으로 구성 할 수 있다. 첫번째 방법은 생성자에(객체의 생성자이므로 객체와 같은 이름을 가진다.) 첫번째 인자로 대각성분을, 두번째 인자로 $0$ 이 아닌 대각성분의 위/아래 성분을, 세번째 인자로 상쌍대각행렬이면 `:U` 를 하쌍대각행렬이면 `:L` 을 입력하는 방법이다.

```txt
In [6]: Bu = Bidiagonal([4, 3, 2, 5], [1, 1, 0], :U)
Out[6]: 4×4 Bidiagonal{Int64, Vector{Int64}}:
 4  1  ⋅  ⋅
 ⋅  3  1  ⋅
 ⋅  ⋅  2  0
 ⋅  ⋅  ⋅  5

In [7]: Bl = Bidiagonal([4, 3, 2, 5], [1, 1, 2], :L)
Out[7]: 4×4 Bidiagonal{Int64, Vector{Int64}}:
 4  ⋅  ⋅  ⋅
 1  3  ⋅  ⋅
 ⋅  1  2  ⋅
 ⋅  ⋅  2  5
```

`Bidiangoal` 타입 행렬을 구성하는 두번째 방법은 이미 존재하는 행렬로부터 대각성분을 포함한 $0$ 이 아닌 성분을 가져오는 방법이다. 다음을 보면 쉽게 이해 할 수 있을 것이다.

```txt
In [9]: A = [1 1 1 1; 2 2 2 2; 3 3 3 3; 4 4 4 4]; Bidiagonal(A, :U)
Out[9]: 4×4 Bidiagonal{Int64, Vector{Int64}}:
 1  1  ⋅  ⋅
 ⋅  2  2  ⋅
 ⋅  ⋅  3  3
 ⋅  ⋅  ⋅  4

In [10]: Bidiagonal(A, :L)
Out[10]: 4×4 Bidiagonal{Int64, Vector{Int64}}:
 1  ⋅  ⋅  ⋅
 2  2  ⋅  ⋅
 ⋅  3  3  ⋅
 ⋅  ⋅  4  4
```

</br>

대각성분, 상대각성분, 하대각성분을 제외한 성분이 모두 $0$ 인 성분을 삼중대각행렬 (Tridiagonal matrix) 라 하며 `LinearAlgebra.jl` 에서는 `Tridiagonal` 타입으로 정의된다. 아래의 행렬 $\bf{C}$ 는 삼중 대각행렬이다.

$$
\bf{C} = \begin{bmatrix} 4 & 1 & 0 & 0 & 0 \\ 2 & 3 & 1 & 0 & 0 \\ 0 & 3 &1& 2 &  0 \\ 0 & 0 & 2& 5 & 1 \\ 0 & 0 & 0 &3 & 6 \end{bmatrix}
$$

삼중대각행렬을 구성하는 방법은 쌍대각행렬을 구성하는 방법과 비슷하게 두가지 방법이다. 하나는 대각행렬 아래 성분들을 나타내는 벡터, 대각성분벡터, 대각성분 위의 성분들을 나타내는 벡터를 차례로 입력하는 것이다.

위의 행렬 $\bf{C}$ 를 구성한다면

```txt
In [11]: C = Tridiagonal([2, 3, 2, 3], [4, 3, 1, 5, 6], [1, 1, 2, 1])
Out[11]: 5×5 Tridiagonal{Int64, Vector{Int64}}:
 4  1  ⋅  ⋅  ⋅
 2  3  1  ⋅  ⋅
 ⋅  3  1  2  ⋅
 ⋅  ⋅  2  5  1
 ⋅  ⋅  ⋅  3  6
```

와 같이 할 수 있다.

다른 방법은 이미 존재하는 행렬로부터 구성하는 것이다.

```txt
In [13]: D = [1 2 3 4 5]' *ones(Int64, 5)'
Out[13]: 5×5 Matrix{Int64}:
 1  1  1  1  1
 2  2  2  2  2
 3  3  3  3  3
 4  4  4  4  4
 5  5  5  5  5

In [13]: Tridiagonal(D)
Out[13]: 5×5 Tridiagonal{Int64, Vector{Int64}}:
 1  1  ⋅  ⋅  ⋅
 2  2  2  ⋅  ⋅
 ⋅  3  3  3  ⋅
 ⋅  ⋅  4  4  4
 ⋅  ⋅  ⋅  5  5
```

`SymTridiagonal` 은 대칭인 삼중대각행렬을 나타내는 타입이다. 대칭행렬이므로 대각행렬의 위 띠와 아래띠가 같다. 이것은 어떻게 구성할까? 여러분이 짐작할 수 있듯이 대각성분과, 띠 성분을 벡터로 입력하면 된다.

```txt
In [14]: SymTridiagonal([1,2, 3, 4, 5], [-1, -2, -3, -4])
Out[14]: 5×5 SymTridiagonal{Int64, Vector{Int64}}:
  1  -1   ⋅   ⋅   ⋅
 -1   2  -2   ⋅   ⋅
  ⋅  -2   3  -3   ⋅
  ⋅   ⋅  -3   4  -4
  ⋅   ⋅   ⋅  -4   5
```

</br>

#### `UpperTriangular`, `LowerTriangular`

상삼각행렬과 하삼각행렬을 다루기 위한 타입은 각각 `UpperTriangular`, `LowerTriangular` 이다. 거기에 대각성분이 $1$ 인 행렬로 특별히 `UnitUpperTriangular`, `UnitLowerTriangular` 타입이 준비되어 있다. 이미 존재하는 행렬로부터 필요한 만큼의 행렬 원소를 취하여 행렬을 구성 할 수 있다.

```txt
In [15]: A = [1.0 2.0 3.0; 4.0 5.0 6.0; 7.0 8.0 9.0]
Out[15]: 3×3 Matrix{Float64}:
 1.0  2.0  3.0
 4.0  5.0  6.0
 7.0  8.0  9.0

In [16]: UpperTriangular(A)
Out[16]: 3×3 UpperTriangular{Float64, Matrix{Float64}}:
 1.0  2.0  3.0
  ⋅   5.0  6.0
  ⋅    ⋅   9.0

In [17]: LowerTriangular(A)
Out[17]: 3×3 LowerTriangular{Float64, Matrix{Float64}}:
 1.0   ⋅    ⋅ 
 4.0  5.0   ⋅ 
 7.0  8.0  9.0

In [18]: UnitUpperTriangular(A)
Out[18]: 3×3 UnitUpperTriangular{Float64, Matrix{Float64}}:
 1.0  2.0  3.0
  ⋅   1.0  6.0
  ⋅    ⋅   1.0

In [19]: UnitLowerTriangular(A)
Out[19]: 3×3 UnitLowerTriangular{Float64, Matrix{Float64}}:
 1.0   ⋅    ⋅ 
 4.0  1.0   ⋅ 
 7.0  8.0  1.0
```

</br>

#### 헤센베르그 행렬

헤센베르그 행렬은 상헤센베르그 행렬(Upper Hessenberg matrix) 과 하헤센베르그 행렬(Lower Hessenberg matrix) 로 이루어진다. 상헤센베르그 행렬(Upper Hessenberg matrix) 은 정사각행렬이며 행렬의 좌하단 모서리 부근이 모두 $0$ 인 행렬이다. 하헤센베르그 행렬(Lower Hessenberg matrix) 는 정사각 행렬이며 행렬의 우하단 모서리 부근이 모두 $0$ 인 행렬이다. 아래의 보기에서 $\bf{H}_U$ 는 상헤센베르그 행렬, $\bf{H}_L$ 은 하헤센베르그 행렬이다.

$$
\bf{H}_U = \begin{bmatrix} 3 & 4 & 2 & 3\\ 1 & 4 & 2 & 3\\ 0 & 2 & 3 & 5 \\ 0 & 0 & 1 & 1\\\end{bmatrix}
,\qquad \bf{H}_L = \begin{bmatrix} 1 & 2 & 0 & 0 \\ 7 & 2 & 3 & 0 \\ 3 & 4 & 3 & 7 \\ 5 & 3 & 1 &2 \end{bmatrix}
$$

Julia 에서는 상헤센베르그 행렬 가운데 첫번째 subdiagonal elements 아래의 성분을 `0` 으로 하는 행렬만 따로 `UpperHessenberg` 타입으로 정의한다. 임의의 정사각 행렬에 대해 `UpperHessenberg` 생성자를 취하면 다음과 같다.

```txt
In [20]: HH = [3  4  2  3; 1  4  2  3; 1  2  3  5 ; 1  2  1  1]
Out[20]: 4×4 Matrix{Int64}:
 3  4  2  3
 1  4  2  3
 1  2  3  5
 1  2  1  1

In [21]: HU = UpperHessenberg(HH)
Out[21]: 4×4 UpperHessenberg{Int64, Matrix{Int64}}:
 3  4  2  3
 1  4  2  3
 ⋅  2  3  5
 ⋅  ⋅  1  1
```

</br>

#### 대칭행렬과 에르미트 행렬

어떤 행렬 $\bf{A}$ 의 행과 열을 바꾼 행렬을 그 행렬의 전치행렬 (transposed matrix) 라 하고 $\bf{A}^T$ 이라 한다. 즉 $(\bf{A}^T)_{ij} = (\bf{A})_{ji}$ 이다. 행렬 $\bf{A}$ 행과 열을 바꾸고 켤레복소수를 취한것을 켤레전치 행렬(conjugate transpose matrix) 혹은 에르미트 전치 행렬(Hermite transpose matrix)라 하고 $\bf{A}^\ast$ 나 $\bf{A}^\dagger$ 라 쓴다. 전자는 수학에서, 후자는 물리학에서 주로 쓰는 표현이다. $\bf{A}=\bf{A}^T$ 이면 **대칭행렬** 이라 한다. $\bf{A}=\bf{A}^\ast$ 이면 에르미트 행렬(Hermitian matrix), 혹은 자기수반 행렬(Self-adjoint matrix) 라 한다. 예를 들어 $\bf{A} =\begin{bmatrix} 2+3i & i \\ 2i & 3\end{bmatrix}$  에 대해,

$$
\bf{A}^T =\begin{bmatrix} 2+3i & 2i \\ i & 3\end{bmatrix},\qquad \bf{A}^\ast = \begin{bmatrix} 2-3i & -i \\ -2i & 3\end{bmatrix}
$$

이다. 행렬 $\bf{A}$ 가 실수 성분만을 가진다면 $\bf{A}^T = \bf{A}^\ast$ 이다.

대칭행렬에 대한 타입은 `Symmetric` 이다. 이미 존재 하는 행렬에서 하삼각부분이나 상삼각부분을 취하여 대칭행렬로 만든다.

```txt
In [22]: A = [1 0 2 0 3; 0 4 0 5 0; 6 0 7 0 8; 0 9 0 1 0; 2 0 3 0 4]
Out[22]: 5×5 Matrix{Int64}:
 1  0  2  0  3
 0  4  0  5  0
 6  0  7  0  8
 0  9  0  1  0
 2  0  3  0  4

In [23]: Supper = Symmetric(A, :U)
Out[23]: 5×5 Symmetric{Int64, Matrix{Int64}}:
 1  0  2  0  3
 0  4  0  5  0
 2  0  7  0  8
 0  5  0  1  0
 3  0  8  0  4

In [24]: Slower = Symmetric(A, :L)
Out[24]: 5×5 Symmetric{Int64, Matrix{Int64}}:
 1  0  6  0  2
 0  4  0  9  0
 6  0  7  0  3
 0  9  0  1  0
 2  0  3  0  4
```

행렬 `A` 의 하삼각 부분을 취하여 대칭행렬로 만들 때는 `Symmetric(A, :U)` 라 하고, 하삼각 부분을 취하여 대칭행렬로 만들 때는 `Symmetric(A, :L)` 라 한다. 이 때 `:U` 나 `:L` 을 입력하지 않으면 `:U` 를 기본값으로 하여 대칭행렬을 만든다.

에르미트 행렬에 대한 타입은 `Hermite` 이며 마찬가지로 `Hermite(A, :U)` 나 `Hermite(A, :L)` 로 에르미트행렬을 만든다. 역시 기본값은 `:U` 이다.

```txt
In [25]: A = [1 0 2+2im 0 3-3im; 0 4 0 5 0; 6-6im 0 7 0 8+8im; 0 9 0 1 0; 2+2im 0 3-3im 0 4];

In [26]: Hupper = Hermitian(A)
Out[26]: 5×5 Hermitian{Complex{Int64}, Matrix{Complex{Int64}}}:
 1+0im  0+0im  2+2im  0+0im  3-3im
 0+0im  4+0im  0+0im  5+0im  0+0im
 2-2im  0+0im  7+0im  0+0im  8+8im
 0+0im  5+0im  0+0im  1+0im  0+0im
 3+3im  0+0im  8-8im  0+0im  4+0im

In [27]: Hlower = Hermitian(A, :L)
Out[27]: 5×5 Hermitian{Complex{Int64}, Matrix{Complex{Int64}}}:
 1+0im  0+0im  6+6im  0+0im  2-2im
 0+0im  4+0im  0+0im  9+0im  0+0im
 6-6im  0+0im  7+0im  0+0im  3+3im
 0+0im  9+0im  0+0im  1+0im  0+0im
 2+2im  0+0im  3-3im  0+0im  4+0im
```

</br>



## `LinearAlgebra.jl` 의 기본 연산자와 함수

우리는 앞서 가우스 소거법과 LU 분해 그리고 그람-그람 슈미트 과정을 통한 QR 분해를 구현하였다. 그러나 앞으로는 이것을 버리고 Julia 에서 제공하는 `LinearAlgebra` 모듈을 사용하도록 하자. Julia 의 `LinearAlgebra` 모듈은 선형대수학에서 사용하는 많은 기능을 포함하고 있다. 여기서는 중요한 것만 설명할 것이며 자세한 것은 [LinearAlgbra.jl 공식 문서](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/)  를 참고하자. `LinearAlgebra` 를 우리가 지금껏 작성한 함수와 그 속도를 비교해보면 `LinearAlgebra` 쪽이 훨씬 빠르다. 그리고 `LinearAlgebra` module 은 많은 프로그래밍 언어에서 사용중이며, 수십년의 역사를 가진 [BLAS(Basic Linear Algebra Subprograms)](https://netlib.org/blas/) 과 [LAPACK(Linear Algebra PACKage)](https://netlib.org/lapack/) 에 기반하여 만들어졌으므로 믿을만 하다. 많은 함수는 희소행렬과 밀집행렬에 대해 공통적으로 사용 할 수 있다.

</br>

### 기본 연산자와 함수

`LininearAlgebra.jl` 은 행렬 `A`($\bf{A}$), `B`($\bf{B}$) 와 벡터 `u`($\bf{u}$), `v`($\bf{v}$), 스칼라 `a`($a$), `b`($b$) 에 대해 다음과 같은 함수를 지원한다. (`LinearAlgebra.jl` 이 지원하는 함수중 일부이다.)


#### 연산자

| 연산자 | 설명 |
|:---------:|:----------------------|
| `+`, `-`, `*` | 수학적으로 정의된 스칼라, 벡터, 행렬 사이의 더하기, 빼기, 곱하기 연산 |
| `\` | `A \ B` 일 경우 `AX==B` 를 만족하는 행렬 `A` 를 구한다. 구하는 방법은 `A` 가 어떤 행렬인지에 따라 달라진다. |
| `/` | 행렬간의 연산일 경우 `(B' / A')` 를 구한다.|
| `u⋅v` (`\cdot`+[tab])  | $\bf{u} \cdot \bf{v}$  |
|`×(u, v)` (`\times`+[tab]) | $\bf{u \times v}$ |


</br> 

#### 기본적인 함수

| 함수 | 설명 | 비고 |
|:------:|:------:|:-------|
| `tr(A)` | $\text{tr}(\bf{A})$ |  |
|`det(A)` | $\det(\bf{A})$ |  |
|`inv(A)` | $\bf{A}^{-1}$| `A` 가 정사각행렬일 경우  |
| `transpose(A)` | $\bf{A}^{T}$| `A` 의 전치행렬 |
|`A'` or `adjoint(A)` | $\bf{A}^\dagger$ | `A` 의 에르미트 전치행렬   |
| `diag(A)` | $[A_{11},\,A_{22},\ldots]$ | 대각성분 |
| `dot(u, v)` | `u⋅v` 와 같다  |
| `dot(u, A, v)` | `dot(u, A*v)` 와 같다 | |
| `cross(u, v)` | `×(u, v)` 와 같다 | 벡터의 외적 |
| `norm(u, p)` or `norm(A, p)`|벡터의 $L_p$-노름 | [벡터와 행렬의 노름과 조건수](#sec-norm_of_vector_and_matrix) 참고 |
| `opnorm(A, p::Real=2)` | 행렬의 $L_p$-노름  | [벡터와 행렬의 노름과 조건수](#sec-norm_of_vector_and_matrix)  참고|
|`normalize(a, p::Real=2)` | 벡터, 행렬의 정규화 | `norm(a, p)==1` 되도록 normalize 한다.|
| `exp(A)` | exponential of $\bf{A}$  | $\displaystyle \sum_{k=1}^\infty \dfrac{\bf{A}^k}{k!}$ |


</br>

## 선형 시스템

우리는 앞서 LU 분해를 통해 선형 시스템을 푸는 코드를 작성하였다. 이제는 `LinearAlgebra.jl` 이 제공하는 `\` 연산자를 이용하면 쉽게 풀 수 있다. 일반적인 정사각 행렬에 대해서는 성긴 행렬이든 밀집 행렬이든 LU 분해를 통해 선형 시스템을 쉽게 풀 수 도록 해 준다. 예를 들어,

```julia
In [1]: using LinearAlgebra

In [2]: A=[4 2 3;3 1 2;3 3 4];b=[2; 1 ;-1]
Out[2]: 3-element Vector{Int64}:
  2
  1
 -1

In [3]: A\b
Out[3]: 3-element Vector{Float64}:
  2.0
  3.0000000000000013
 -4.000000000000001
```

와 같이 풀 수 있다. 

</br>


