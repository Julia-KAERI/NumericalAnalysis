---
title: "일변수 방정식의 해"

number-sections: true
number-depth: 2
crossref:
  chapters: false
---



우리는 수학을 배운 이후 $2x-6=0$ 와 같은 방정식의 해를 구하는 것을 배워 왔다. 여기서는 일변수 방정식, 그중에서도 실함수에 대한 실수해를 구하는 방법을 알아본다. 

많은 경우 우리는 해가 존재하는지 아닌지 여부를 쉽게 알 수 있다. 예를 들어 3차방정식의 경우는 최소한 하나의 해가 존재하며 복잡하긴 하지만 우리는 그 계수만을 가지고 근을 알 수 있는 공식이 존재한다는 것을 안다. 그러나 5차방정식 혹은 그 이상의 홀수차 방정식의 경우는 그 계수만으로 해를 알 수 있는 근의공식이 존재하지 않지만 최소한 하나의 해가 존재한다는 것을 알고 있다. 이 장에서 다루는 수치해석적인 방법을 통해 어떤 구간 안에서 해가 하나 이상 존재하는 것을 미리 알고 있을 때, 그 구간에서의 해를 하나 구할 수 있다.

또 하나 이 장에서 새롭개 배우는 것은 소위 반복법 (iteration) 이다. 지금까지는 이미 존재하는 함수나 데이터를 통해 우리가 구하고자 하는 값을 직접적으로 구했다. 그러나 많은 경우 직접적으로 이 값을 구할 수 없으며, 이런 경우에는 반복적인 계산을 통해 우리가 구하고자 값에 가까운 값을 구할 수 있다. 이 때 우리가 이 반복적인 실행을 통해 원하는 값을 얻었는지를 판단할 수 있는 근거가 필요한데 이 값들을 **허용범위(tolerence)** 라고 한다. 예를 들어 우리가 방정식 $f(x)=0$ 의 어떤 해가 $(-1.0\times 10^{-8}, \, 1.0\times 10^{-8})$ 구간에 존재한다는 것을 알았다고 하자. 이 경우 해를 $x=0$ 으로 잡으면 최대 오차는 $1.0 \times 10^{-8}$ 인데 어떤 경우는 부족하지만 어떤 경우는 충분히 만족스러울 수 있다. 만약 이정도의 오차가 충분히 만족스럽다면 허용범위를 구간의 범위가 $2.0 \times 10^{-8}$ 보다 작다고 정하면된다. 문제에 따라 다양한 허용 범위를 조합하여 사용 할 수도 있다.

</br>



## 이분법 (Bisection Method)

함수 $f$ 가 $(a,\,b)$ 에서 연속이며, $f(a)<0$ 이고 $f(b)>0$ 이거나 혹은 $f(a)>0$ 이고 $f(b)<0$ 이라 하자. 즉 $f(a)\cdot f(b)<0$ 이라고 하자. [중간값 정리](06_calculus_of_one_variable_function.qmd#thm-intermediate_value_theorem) 에 따라, $f(a)\cdot f(b)<0$ 이면, $(a,\,b)$ 구간의 최소한 한 점에서 $f(x)=0$ 의 해가 존재한다는 것을 안다. 이 조건만으로는 해가 $(a,\,b)$ 구간에서 몇개인지는 모르지만 최소한 하나는 존재한다는 것을 알 수 있다. 이분법은 이 조건이 만족하는 구간에서 하나의 근사적인 해를 구하는 방법이다.

1. 일단 $f(a)<0,\, f(b)>0$ 인 경우에 대해 생각하자. $c=\dfrac{a+b}{2}$ 로 놓으면 $a<b<c$ 이다.[$f(a)>0,\,f(b)<0$ 인 경우에도 같은 방법을 쓸 수 있다는것은 쉽게 이해 할 수 있을 것이다.]{.aside}

2. 우연히도 $f(c) =0$ 이면 우리는 원하는 것을 얻었으므로 끝이다. $f(c)>0$ 이면, $f(a)\cdot f(c)<0$ 이므로 역시 중간값 정리에 의해 $(a,\,c)$ 구간에 해가 반드시 존재한다. $(c,\,b)$ 구간에 존재여부는 이 조건에서는 알 수 없으며, 우리는 이 구간은 이제 잊는다. $f(c)<0$ 이면 $f(c)\cdot f(b)<0$ 이므로 $(c,\,b)$ 구간에 해가 존재한다.

3. 이제 우리는 해가 반드시 존재하는 원래 구간 길이의 1/2 인 새로운 구간을 얻었다. 이제 1. 로 돌아가 새로운 구간에서 다시 수행한다.

이 방법을 한번 쓸 때 마다 해가 존재하는것이 확실한 구간이 이전보다 $\frac{1}{2}$ 씩 준다.  이것을 $n$ 번 수행하면, 운 좋게도 $f(c)=0$ 이 되지 않는 한, 해가 존재하는 구간의 길이는 $\frac{1}{2^{n}}|b-a|$ 로 계속 준다. 10번 수행하면 처음 시작 구간의 약 0.1% 로, 100 번 하면 약 백만분의 일로 준다. 




</br>

### 이분법 과정

![이분법](ch06_finding_root/bisection_concept.png)

이 과정을 프로그래밍 입장에서 다시 정리해보자.  일단 처음 주어지는 함수 $f(x)$ 와 $a,\,b$ 에 대해 $a<b$ 로 주어졌다고 하자. 그리고 우리는 실제의 근 $x_0$ 와 우리가 구한 근의 차이를 어떤 작은 양수 $\delta$ 보다 작게 하고자 한다. 이 $\delta$ 가 허용범위이다.

1. $a_0=a,\,b_0=b,\,c_0=\dfrac{a+b}{2}$ 로 놓는다.  만약 $f(a_0) \cdot f(c_0)<0$ 이면  역시 중간값 정리에 의해 $(a_0,\, c_0)$ 구간에 해가 존재함을 알 수 있다. 그렇다면 $a_1=a_0,\, b_1=c_0$ 으로 놓는다. 반대로 $f(a_0)\cdot f(c_0)>0$ 이면 $f(c_0)\cdot f(b_0)<0$ 이므로 $(c_0,\,b_0)$ 구간에 해가 존재한다. 이때는 $a_1=c_0,\, b_1=b_0=b$ 로 놓는다. $f(c_0)=0$ 이면 $c$ 이 $f(x)=0$ 의 해이므로 더이상 진행하지 않는다.

2. $a_n<b_n$ 에 대해 $f(a_n)\cdot f(b_n)<0$ 이라 하자. $|b_n-a_n|<2\delta$ 이면 실제의 근 $x_0$ 와 $c_n =\dfrac{a_n+b_n}{2}$ 의 차이는 $\delta$ 보다 작기 때문에 $c_n$ 이 우리가 구하고자 하는 수치적인, 그리고 근사적인 근이 된다. $|b_n-a_n|\ge 2\delta$ 이면, $c_n =\dfrac{a_n+b_n}{2}$ 이라 놓는다. $f(c_n)=0$ 이면 우리는 하나의 해를 구했으므로 종료한다. $f(a_n)\cdot f(c_n)<0$ 이면 $(a_n,\,c_n)$ 구간에서 하나의 해가 존재하므로 $a_{n+1}=a_n,\, b_{n+1}=b_n$ 으로 놓고 이 과정을 계속 한다. $f(a_n)\cdot f(c_n)>0$ 이면 $f(b_n) \cdot f(c_n)<0$ 이므로 $a_{n+1}=c_n,\, b_{n+1}=b_n$ 으로 놓는다.

</br>

이제 이것을 줄리아로 구현해 보자. 실제 프로그래밍 상에서는 $a_n$ 이나 $b_n$ 계산하지 않고, $a,\,b$ 의 변수값을 계속 바꾸도록 한다. $a_n$ 과 $b_n$ 의 히스토리는 대부분 중요하지 않다.

</br>

### 이분법에 대한 julia 구현

이분법을 `bisection` 함수로 구현해보자. 우선 인자로 해를 구하고자 하는 함수(`f`) 와, 양 끝 구간(`a`, `b`), 그리고 허용범위(`xtol`)가 필요하다. 이분법은 잠시 뒤에 보이겠지만 허용범위가 양수일 경우 유한번의 반복으로 허용범위 내의 근사적 해를 구한다. 실제 계산에서는 필요하지 않을 수도 있지만 여기서는 몇번의 반복으로 해를 구했는지 확인하기 위해 `bisection` 함수가 근사적 해와 반복 횟수를 반환하도록 한다.

```{.julia code-line-numbers="true"}
function rootfinding_bisection(
    f::Function,                    # 함수
    a::Real,                        # 구간값 1
    b::Real,                        # 구간값 2
    xtol::Real = 1.0e-8,            # 해의 오차의 허용 범위
    etol::Real = 1.0e-10)           # 해의 함수값의 허용 범위
    Niter = 0
    a, b = minmax(a, b)
    f(a)*f(b) <= 0 || error("f(a)*f(b) should be negative") 
    c = (a+b)/2
    while ((b-a) > 2*xtol) || (abs(f(c))<etol)
        Niter +=1
        
        if f(c) == 0.0
            break
        elseif f(a)*f(c) < 0 
            a, b = a, c
        else 
            a, b = c, b 
        end
        c = (a+b)/2
    end
    return c, Niter
end
```

이제 이분법을 이용하여 $\sqrt{2}$ 의 근사값을 구할 수 있다. $\sqrt{2}$ 는 $f(x)=x^2-2$ 의 근이므로

```julia
rootfinding_bisection(x -> x^2-2, 0.0, 4.0)
```

라 하면, `sqrt2` 의 값은 다음과 같다.

```sh
(1.4142135605216026, 28)
```

</br>

::: {.callout-note}
앞의 코드에서 `f(a)*f(b) <= 0 || error("f(a)*f(b) should be negative")` 는 소위 **단락 계산 (short-circit evaluation)** 을 사용한 표현이다. 표현식 `a && b` 에서, 하위 표현식 `b`는 오직 `a` 가 `true` 일때만 실행된다. 반면 표현식 `a || b` 에서, 하위 표현식 `b` 는 오직 `a` 가  `false` 로 계산될 때만 계산을 받는다. 왜냐 하면, `a` 가 `false` 이면, `b` 의 값에 관계없이 `a && b` 는 무조건 `false` 가 되고, `a` 가 `true` 이면, `b` 의 값에 관계없이 `a && b` 는 무조건 `true` 가 되기 때문이다. 따라서 `f(a)*f(b)` 가 0 보다 큰 경우에만 에러를 발생시킨다. 이것은

```julia
if f(a)*f(b) <= 0
    error("f(a)*f(b) )
```

와 같은 표현이다.
:::

</br>


## 고정점 반복법 (Fixed Point Iteration)

함수 $f(x)$ 에 대해 $f(p)=p$ 를 만족하는 점 $p$ 를 $f$ 의 고정점 (fixed point) 라 한다. 고정점 자체가 중요한 경우도 많으며, 방정식의 해를 찾는것과 밀접하게 연관되어 있다. $g(x) = f(x)-x$ 라 놓으면 $f(x)$ 의 고정점을 찾는 것은 $g(x)$ 의 해를 찾는 문제와 같은 문제라는 것을 쉽게 이해 할 수 있을 것이다. 역으로, 함수 $g(x)=0$ 의 해를 찾는 문제는 $f(x) = g(x)  + x$ 의 고정점을 찾는 문제와 동일한 문제이다.

고정점 반복법이 가능한 이유는 아래의 고정점 정리 때문이다.

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#thm-fixed_point}
#### 고정점 정리 {#sec-thm_fixed_point}

$f$ 가 $[a,\,b]$ 구간에서 연속이며 $f([a,\,b])\subset [a,\,b]$ 이면,

&emsp; ($1$) $f(p)=p$ 를 만족하는 고정점 $p$ 가 $[a,\,b]$ 구간에 존재한다.

&emsp; ($2$) 모든 $x,\,y \in [a,\,b]$ 에 대해 $|f(x)-f(y) |\le \lambda |x-y|$ 를 만족하는 $\lambda\in\mathbb{R}$ 이 존재하며,  $0<\lambda<1$ 이면 고정점은 유일하다.

&emsp; ($3$) ($2$)의 조건을 만족시킬 때, 임의의 $p_1\in [a,\,b]$ 와 $p_{n+1}=f(p_n)$ 으로 정의되는 수열 $\langle p_n\rangle$ 은 수렴한다.

:::

</div>

</br>

::: {.proof}
($1$) $f(a)=a$ 이거나 $f(b)=b$ 이면 자명하므로 $f(a)\ne a,\, f(b) \ne b$ 인 경우만 생각한다. $g(x)=f(x)-x$ 라 하면 가정에 의해 $g(a)\ne 0,\, g(b) \ne 0$ 이다. 모든 $x\in [a,\,b]$ 에 대해 $a<f(x)<b$ 이므로 $g(a)=f(a)-a>0$ 이며 $g(b)=f(b)-b<0$ 이다. $g(x)$ 역시 $[a,\,b]$ 에서 연속이므로 중간값정리에 의해 $g(p)=0$ 인 $p\in(a,\,b)$ 가 존재해야 한다.  즉 $f(p)=p$ 를 만족하는 점 $p\in [a,\,b]$ 가 존재한다.

($2$) 고정점이 두개 이상 존재한다고 가정하고 두개의 임의의 고정점을 $p,\,q$ 라 하자. 그렇다면,
$$
|p-q | = |f(p)-f(q)| \le \lambda |p-q|< |p-q|
$$

이므로 모순이다. 따라서 고정점은 유일하다.

($3$) $p$ 를 유일한 고정점이라고 하자.

$$
|p-p_{n+1}| = |f(p) - f(p_n)| \le \lambda |p-p_n| \le \lambda^{n-1}|p-p_1|
$$

이므로 $\displaystyle \lim_{n \to \infty} p_n = p$ 이다. $\square$

::: 

</br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#cor-for_fixex_point_theorem}

$[a,\,b]$ 구간에서 미분가능한 함수 $f(x)$ 가 $f([a,\,b])\subset [a,\,b]$ 이며, 어떤 양수 $0<\gamma<1$ 에 대해 $x\in [a,\,b] \implies |f'(x)|<\gamma$ 이면, $[a,\,b]$ 구간에서 유일한 고정점을 가진다.

:::

</div>

</br>

::: {.proof}
고정점 정리의 ($2$) 를 생각하자. $[a,\,b]$ 구간에서 $f$ 가 미분가능이므로 중간값 정리에 의해 $\dfrac{f(x)-f(y)}{x-y}=f'(c)$ 인 $c\in [a,\,b]$ 가 존재하며, $|f'(x)|<\gamma<1$ 이므로
$$
|f(x)-f(y)|=|f'(c)||x-y|<\gamma |x-y|
$$

이다. 따라서 $f(x)$ 는 $[a,\,b]$ 구간에서 유일한 고정점을 가진다. $\square$

:::

</br>

::: {#exm-fixed_point_1}

함수 $f(x) = x^2-2$ 를 생각하자. $f(0)=-2$ 이며 $f(2)=2$ 이므로 $[0,\,2]$ 구간에서 해가 반드시 존재한다. 


:::

::: {#exm-fixed_point_2}

이제 고정점 정리를 이용하여 $f(x)=x^3 − 2x^2 − 1 = 0$ 의 해를 $[1,\,3]$ 구간에서 구해보자. $g(x) = x-f(x)$ 로 놓으면, $g(1) = 3,\, g(3)=-5$ 이므로  고정점 정리의 가정 $g([a,\,b]) \subset [a,\,b]$ 에 위배된다.
$p$ 가 $f(x)$ 의 해이면 $p^3 = 2p^2+1$ 이므로 $p$ 는 $h(x) = (2x^2+1)^{1/3}$ 의 해이다. $h(1) \approx 1.442,\, h(3) \approx 2.668$ 이므로 $h(x)$ 는 고정점 정리의 제 1 조건을 만족한다. 또한

$$
h'(x) = \dfrac{4x}{3(2x^2+1)^{2/3}}
$$

이며, $x\in [1, 3]$ 이므로 $x>0$ 이다. 따라서 $[1,\,3]$ 구간에서,

$$
|h'(x) | = \dfrac{4|x|}{|3(2x^2+1)^{2/3}|} \le \dfrac{4|x|}{|3(2x^2+1)^{1/2}|} \le \dfrac{4|x|}{|3(2x^2)^{1/2}|}  < \dfrac{4}{3\sqrt{2}} <0.943< 1
$$

이므로 $h(x)$ 는 $[1,\,3]$ 구간에서 유일한 고정점을 가진다.

:::


```julia
function fixedpoint(f::Function, xi::T, xtol::T=1.0e-10, MaxIter::Int64 = 100_000)::T where T<:AbstractFloat
    Niter = 0
    for i in 1:MaxIter
        c = f(xi)
        if abs(c-xi) < xtol
            return c
        else
            xi = c
            Niter += 1
        end
    end
    error("최대 반복 횟수 $MaxIter 에 도달하였으나 답을 찾지 못함.")
end

h(x) = (2x^2+1)^(1/3)
fixedpoint(h, 2.0)
```

여기서 얻은 결과는 `2.2055694302615003` 이다.  


</br>

## 뉴턴 방법 (Newton-Method)

![뉴턴 방법](ch06_finding_root/newton_method.png)

함수 $f(x)$ 가 미분가능하다고 하자. 그리고 $(a,\,b)$ 구간에서 $f(x)=0$ 의 해가 존재하며, 이 구간에서 도함수 $f'(x)$ 가 $0$ 보다 항상 크다고 하자. 해는 정확히 모르지만 대략 $p_0 \in (a,\,b)$ 근처임을 안다고 하자. 테일러 정리에 의해 $f(x)$ 는 $p_0$ 근처에서 대략
$$
f(x) \approx f(p_0) + f'(p_0)(x-p_0)
$$

이다. 이제 $f_0 (x) =  f(p_0) + f'(p_0)(x-p_0)$ 라 놓고 $f_0(x) = 0$ 의 해를 구하여 $p_1$ 이라 하면,

$$
p_1 = p_0 - \dfrac{f(p_0)}{f'(p_0)}
$$

가 된다. 이제 $f(x)$ 를 $p_1$ 에서의 1차 다항식으로 전개한 $f_1(x)$ 는

$$
f_1(x) = f(p_1) + f'(p_1)(x-p_1)
$$

이 되며 이 식의 해를 $p_2$ 라 놓는다. 즉 $p_2 = p_1 - \dfrac{f(p_1)}{f'(p_1)}$ 이다. 이 과정을 반복하여 해를 얻는 방법을 **뉴턴 방법(Newton method)** 혹은 **뉴턴-랩슨 방법(Newton-Raphson) method** 라고 한다. 

</br>

앞서 배운 이분법과는 달리 뉴턴방법은 시작점이 해와 충분히 가깝지 않다면 해를 발견하지 못할 수도 있다. 뉴턴 방법 역시 조건이 만족할 때 까지 반복문을 수행하는데 이 반복이 끝나지 않을 수 있다. 


</br>

### 무한루프

수치해석은 기본적으로 `for ~ end` 문이나 `while ~ end` 같은 반복문이 아주 많이 쓰인다. 이 가운데 `while (condition) ~ end` 구문은 조건이 참인지 아닌지 여부만을 따져 수행을 반복하기 때문에 잘못하면 수행이 끝나지 않을 수 있다. 예를 들어,

```julia
v = 1
while v<10
    v=v*1
end
```

같은 코드는 종료되지 않는다. 이분법의 경우는 상관 없지만 어떤 알고리즘을 루프로 구현할 경우, 다양한 원인으로 인해 무한루프에 빠질 수 있다. 프로그래밍에 익숙한 사용자라면 일정 시간이 흘러도 결과가 나오지 않으면 무한루프에 빠졌다는 것을 쉽게 알 수 있을 수도 있다. 그러나 함수값 하나 얻는 데 시간이 오래 결리는 경우는, 수행시간이 오래 지났더라도 이것이 정상적인 실행중인지, 무한루프에 빠졌는지 불확실할 경우도 있다. 그래서 이런 경우는 보통 최대 반복 횟수를 정해놓고 이 횟수에 도달하면 에러를 발생시키는 등으로 정상적인 결과를 얻지 못했다는 것을 알려 주는것이 좋다.

</br>

### 뉴턴 방법의 구현


1. $f(x)=0$ 을 만족하는 해가 대략 $p_0$ 근처임을 안다.

2. $p_{n+1} = p_{n}- \dfrac{f(p_{n})}{f'(p_{n})}$ 을 계속 반복

이를 구현한 코드는 아래와 같다. 앞서 언급했듯이 뉴턴 방법은 분할법과는 달리 항상 해를 발견하는 것을 보장하지 않는다. 따라서 무한 루프에 빠지는 것을 방지하기 위해 최대 반복 횟수(`MaxIter`) 를 함수의 인자로 입력한다. $p_n$ 에서의 미분값이 $0$ 일 경우 $p_{n+1}$ 을 구할 수 없으며, $|f'(p_n)|$ 이 매우 작을 경우 원하는 범위를 벗어나기 때문에 미분값의 절대값의 최소값을 지정하여 그 절대값보다 작을 경우는 에러를 발생시키도록 한다. 이분법의 경우는 구간을 좁혀가는 방법이기 때문에 구간의 범위를 허용범위로 정했지만 뉴턴 방법에서는 $|f(p_n)|$ 값이 특정 값 $\delta>0$ 보다 작을 때 $x_n$ 을 근사적 해로 간주하며 $\delta$ 를 허용범위로 한다. 다음 함수에서는 이 허용범위를 `etol` 인자로 전달한다. 

```{.julia code-line-numbers="true"}
function rootfinding_newton(
    f::Function,                    # 함수
    df::Function,                   # 도함수
    p::Real,                        # 시작값
    MaxIter::Int64=100_000,         # 최대 반복 횟수
    etol::Real = 1.0e-8,            # 해의 함수값의 허용 범위
    dfmin::Real = 1.0e-6)           # 미분값의 절대값의 허용되는 최소값
    
    Niter = 0
    for i in 1:MaxIter
        if abs(f(p)) < etol
            break
        elseif abs(df(p)) < dfmin 
            error("df ≈ 0.0")
        end
        p = p - f(p)/df(p)
        Niter += 1       
        
        if abs(f(p)) < etol 
            return (p, Niter)
        end
    end
    error("최대 반복 횟수 $MaxIter 에 도달하였으나 답을 찾지 못함")
end


f2(x) = x*(x-1.)*(x-2.)+5
df2(x) = 3*x^2-6*x+2
rootfinding_newton(f2, df2, 1.2)
```

$f_2(x) = x(x-1)(x-2)+5$ 에 대한 해를 구하였으며, 시작점 $x_i = 1.2$ 로 부터 추산했을 때 그 결과는 다음과 같다.

```sh
(-0.9041608591349207, 24)
```

만약 $0.0$ 부터시작한다면, 즉 `newton_method(f2, df2, 0.0)` 를 실행한다면,

```sh
(-0.9041608591349207, 7)
```

이 된다.

</br>


### 뉴턴 방법의 단점과 수렴

이분법은 두 시작점에서의 함수값의 곱이 음수이면 무조건 하나의 해를 원하는 오차 내에서 찾을 수 있다. 그러나, Newton method 는 해를 찾을 수 없는 경우도 생기는데 가장 대표적인 경우는 위의 과정중에 어떤 $x_k$ 에 에서 $f'(x_k)=0$ 인 경우이다. 또한 시작점이 해와 충분히 가깝지 않을 경우 발산 할 수 있다. 우리는 뉴턴 방법을 통해 무조건 해를 갖는 조건을 보일 수 있다.


<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#thm-convergence_of_newton_method}

#### 뉴턴 방법의 수렴정리 {#sec-convergence_of_newton_method}

$f\in C^2_{[a,\,b]}$ 인 실함수 $f$ 에 대해 $f(p)=0$ 이며 $f'(p)\ne 0$ 이라 하자. 그렇다면 어떤 $\delta>0$ 이 존재하여 $p_1\in [p-\delta,\, p+\delta]$ 이라면 뉴턴 방법을 통해 얻은 수열 $\langle p_n\rangle$ 은 $p$ 로 수렴한다.
:::
</div>

</br>

::: {.proof}

뉴턴 방법에 의해 $p_n$ 이 정해졌을 때 $p_{n+1}$ 은 직선 $f'(p_n) (x-p_n) + f(p_n) = 0$ 의 해이다. 즉, 

$$
p_{n+1}= p_n - \dfrac{f(p_n)}{f'(p_{n})}
$$

이다. $g(x) = x-\dfrac{f(x)}{f'(x)}$ 라 하자. $f(p)=0$ 이므로 $g(p)=p$ 이다. $f \in C_2{[a,b]}$ 이고 $p\in p=(a,\,b)$ 이며 $f'(p) \ne 0$ 이므로 어떤 $p$ 의 근방에 대해 미분값이 $0$ 이 아니다. 즉 어떤 $\delta_1>0$ 에 대해 $t\in I_1=[p-\delta_1,\, p+\delta_1]$ 이면 $f'(t)\ne 0$ 이다. $g(x)$ 는 $C^1_{I_1}$ 이므로 도함수가 존재한다.

$$
g'(x) = 1-\dfrac{(f'(x))^2-f(x) f''(x)}{(f'(x))^2} = \dfrac{f(x)f''(x)}{(f'(x))^2}
$$

이며 $g'(p)= 0$ 이다. $g$ 의 도함수가 연속이며 $g'(p)=0$ 이므로 어떤 $k\in (0,\,1)$ 에 대해 $|g'(x)|\le k$ 인 구간 $I_2=[p-\delta_2,\, p+\delta_2]$ 가 존재한다. $\delta = \min(\delta_1,\delta_2)$ 라 하면 구간 $I=[p-\delta,p+\delta]$ 에 대해 $t\in I$ 이면 $|g'(t)|\le k,\, 0<k<1$ 이며 $f'(t)\ne 0$ 이다.

평균값 정리에 의해 $t\in I$ 이면 $g(t)-g(p) = g'(\xi)(t-p)$ 인 $\xi\in I$ 가 존재한다. $0<|g'(\xi)|<1$ 이므로, 

$$
|g(t)-p| = |g(t)-g(p)| < |g'(\xi)||t-p| \le k|t-p| < |t-p|
$$

$|t-p|<\delta$ 이므로 $|g(t)-p|<\delta$ 이다. 따라서 $g$ 는 $[p-\delta,\, p+\delta]$ 에서 $[p-\delta, p+\delta]$ 로의 함수이다. 고정점 정리(@thm-fixed_point) 에 의해 $p_{n+1}=g(p_n)$ 으로 정의된 수열은 $p$ 로 수렴한다. $\square$
:::

</br>

## 할선법 (Secant method)

![할선법](ch06_finding_root/secant_method.png)

뉴턴 방법에서는 함수 $f(x)$ 뿐만 아니라 도함수 $f'(x)$ 도 필요하다. 그러나 도함수 $f'(x)$ 가 매우 복잡하거나 하여, 도함수를 직접적으로 인자로 주기 힘든 경우가 생길 수 있다. 이 때 시작점이 아닌 두 $x$ 좌표 $p_0,\,p_1$ 을 함수의 인자로 주고, 도함수가 아닌 수치적으로 계산한 미분의 근사값 $\dfrac{f(p_n)-f(p_{n-1})}{p_n -p_{n-1}}$ 을 사용하는 것을 할선법이라 한다. 즉 주어진 $p_{n-1},\, p_n$ 에 대해 $p_{n+1}$ 을 다음과 같이 얻는다.

$$
p_{n+1} = p_n - \dfrac{f(p_n)}{g(p_n)} \,\qquad \textrm{where } g(p_n)=\dfrac{f(p_n)-f(p_{n-1})}{p_n -p_{n-1}}.
$$


```julia
function rootfinding_secant(
    f::Function,                # 함수
    p0::Real,                   # 시작값 1
    p1::Real,                   # 시작값 2
    MaxIter::Int64 = 100_000,   # 최대 반복 횟수
    etol::Real = 1.0e-8,        # 해의 함수값의 허용 범위
    dfmin::Real = 1.0e-6)       # 도함수의 근사값의 절대값에 허용되는 최소값
    
    Niter = 0
    
    for i in 1:MaxIter
        gx = (f(p1)-f(p0))/(p1-p0)
        if abs(f(p1)) < etol 
            return p1, Niter
        elseif abs(gx)<dfmin
            error("df ≈ 0.0")
        end
        p0, p1 = p1, p1 - f(p1)/gx
        Niter += 1
    end
    error("최대 반복 횟수 $MaxIter 에 도달하였으나 답을 찾지 못함.")
end
```

이것에 대해 뉴턴법과 비교해보았다.

```julia
f2(x) = x*(x-1.)*(x-2.)+5
df2(x) = 3*x^2-6*x+2
rootfinding_newton(f2, df2, 0.0)
rootfinding_secant(f2, 0.0, 0.1)
```

를 수행하면

```sh
(-0.9041608591349207, 7)
(-0.9041608591355101, 10)
```

의 결과를 얻었다. 뉴턴 방법은 7회, 할선법은 10회의 반복으로 원하는 범위의 해를 얻었다.

</br>

## Regula Falci

이분법과 할선법을 결합시킨 방법이다. 우선 구간 $[a,\,b]$ 에서 연속인 함수 $f(x)$ 의 해를 구하고자 하며 $f(a)\cdot f(b)<0$ 이라 하자. 이분법에서는 $c=\dfrac{a+b}{2}$ 에서의 $f(c)$ 값에 대해 $f(a)\cdot f(c)<0$ 인지 여부에 따라 다음 구간이 이전 구간의 반으로 줄었다면 Regula false 에서는 

$$
c = b-f(b) \cdot \dfrac{b-a}{f(b)-f(a)}
$$

에 대한 $f(c)$ 를 생각한다. 이 방법은 도함수가 필요 없으며, 많은 경우 이분법보다 빨리 해를 찾는다는 장점이 있다.

```{.julia code-line-numbers="true"}
function rootfinding_regula_falci(
    f::Function,                    # 함수
    a::Real,                        # 구간값 1
    b::Real,                        # 구간값 2
    MaxIter::Int64 = 100_000,       # 최대 반복 회수
    xtol::Real = 1.0e-8,            # 해의 오차의 허용 범위
    etol::Real = 1.0e-8,            # 해의 함수값의 허용 범위
    dfmin::Real = 1.0e-6)           # 도함수의 근사값의 절대값에 허용되는 최소값

    a, b = minmax(a, b)
    @assert f(a)*f(b) < 0

    Niter = 0

    for i in 1:MaxIter
        Niter +=1
        gx =  (f(b)-f(a))/(b-a)
        c = b-f(b)/gx
        if (abs(b-a)<xtol) || (abs(f(c))<etol)
            return c, Niter
        elseif abs(gx) < dfmin 
            error("df ≈ 0.0")
        end
        
        
        if f(b)*f(c) < 0 
            a, b = b, c
        else 
            a, b = a, c
        end
    end
    error("최대 반복 횟수 $MaxIter 에 도달하였으나 답을 찾지 못함.")
end
```

</br>

### 네가지 방법의 비교

$f(x)=x-\cos(x)$ 에 대한 해를 구해보자. $f'(x) = 1+\sin(x)$ 이므로 $f(x)$ 는 단조증가함수이다. $f(0)=-1<0$ 이며 $f(\pi/2) = \pi/2>0$ 이므로 우리는 $(0,\, \pi/2)$ 구간에서 단 하나의 해가 존재한다는 것을 알 수 있다. 우리는 앞서 네가지 방법에서 해를 발견할 경우 해와 반복 수행 햇수를 반환하도록 코딩하였다. 

```julia
f(x) = x-cos(x)
df(x) = 1+sin(x)
println(rootfinding_bisection(f, 0, π/2))
println(rootfinding_newton(f, df, 0.0))
println(rootfinding_secant(f, 0, π/2))
println(rootfinding_regula_falci(f, 0, π/2))
```

그 결과는 다음과 같다.

```sh
(0.7390851321023699, 27)
(0.739085133385284, 4)
(0.739085133034638, 5)
(0.7390851292482057, 9)
```

이분법이 가장 많은 반복을 수행하였으며 뉴턴법이 가장 적은 반복을 수행했다. 

## 오차 해석

### 수학적 기초


::: {.callout-note appearance="minimal"}
::: {#def-order_of_convergence}

#### 수렴 속도 (order of convergence)

수열 $\langle p_n \rangle$ 이 $p$ 로 수렴하며, 모든 $n$ 에 대해 $p_n \ne p_0$ 라고 하자. 이 때

$$
\lim_{n \to \infty} \dfrac{| p_{n+1}-p|}{|p_n-p|^\alpha} = \mu
$$

를 만족하는 양수 $\mu$ 와 $\alpha\ge 1$ 가 존재한다면 $\alpha$ 를 수열 $\langle p_n \rangle$ 의 **수렴 속도** 라고 하고 $\mu$ 를 근사적 **오차 상수(asymptotic error constant)** 라고 한다. 특히 $\alpha=1$ 인 수열은 $\mu<1$ 일 때에만 수렴하며 이 경우 **선형 수렴 수열** 이라고 한다. $\alpha=2$ 인 수열은 **이차 수렴 수열** 이라고 한다.

:::

:::



</br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

::: {#thm-linearly_convergent_sequence}

실함수 $g\in C[a,\,b]$  가 $g([a,\,b]) \subset [a,\, b]$ 라 하자. @thm-fixed_point 에 의해 고정점 $p\in [a,\,b]$ 가 존재한다. 또한 어떤 양수 $\lambda <1$ 가 존재하여 모든 $x\in (a,\,b)$ 에 대해 $|g'(x)|<\lambda$ 라 하자. $g'(p)\ne 0$ 라면 $p_0 \ne p$ 에 대해 수열 $\langle p_n \rangle$ 을

$$
p_{n+1} = g(p_{n}),\qquad n=0,\,1,\,2,\ldots
$$

로 정의하자. 이 때 이 수열은 $[a,\,b]$ 의 고정점 $p$ 로 수렴하는 선형 수렴 수열이다.

:::

</div>
</br>

::: {.proof}

평균값 정리에 의해 각각의 $n=1,\,2,\ldots$ 에 대해 

$$
\dfrac{p_{n+1}-p}{p_{n}-p} = \dfrac{g(p_n)-g(p)}{p_n-p} \le g'(\xi_n)
$$

를 만족하는 $\xi_n$ 이 $p_n$ 과 $p$ 사이에 존재한다. 즉 $|p_{n+1}-p| \le |g'(\xi_n)(p_n-p)|$ 이다. $\langle p_n \rangle$ 이 $p$ 로 수렴하므로 $\langle \xi_n\rangle$ 도 $p$ 로 수렴한다. $g'$ 이 $(a,\,b)$ 구간에서 연속이므로,

$$
\lim_{n \to \infty} g'(\xi_n) = g'(p) \ne 0
$$

이며, 따라서,

$$
\lim_{n \to \infty} \dfrac{|p_{n+1}-p|}{|p_n-p|} = |g'(p)|
$$

이다. $g'(p)\ne 0$ 이므로 $\langle p_n \rangle$ 은 선형 수렴 수열이다. $\square$

:::

 -- to be filled --